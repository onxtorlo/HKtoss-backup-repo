"""
QLoRA Fine-tuning Script for Korean Project Analysis
íŒŒì¼ëª…: train_qlora.py

ì‹¤í–‰ ë°©ë²•:
python train_qlora.py --config qlora_config.yaml
"""

import logging
from dotenv import load_dotenv
from dataclasses import dataclass, field
import os
import random
import torch
import json

from datasets import load_dataset
from datasets import Dataset
from transformers import AutoTokenizer, TrainingArguments, BitsAndBytesConfig
from trl.commands.cli_utils import TrlParser
from transformers import (AutoModelForCausalLM, AutoTokenizer, set_seed)
from trl import setup_chat_format
from peft import LoraConfig, get_peft_model, TaskType
from trl import SFTTrainer

from sklearn.model_selection import train_test_split
from huggingface_hub import login

load_dotenv()

api_key = os.getenv('HUG_API_KEY')
login(token=api_key)

### ë°ì´í„°ì…‹ ì¤€ë¹„ 
with open('../data/finetuning_dataset.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

system_prompt = """
ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  êµ¬ì¡°í™”í•˜ì—¬ êµ¬ì²´ì ì¸ ê°œë°œ ê³„íšì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

## ì£¼ìš” ì—­í• ê³¼ ëŠ¥ë ¥:

### 1. í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€
- ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë‚˜ ì„¤ëª…ì„ ê¹Šì´ ìˆê²Œ ë¶„ì„í•©ë‹ˆë‹¤
- í•µì‹¬ ê¸°ëŠ¥, ëŒ€ìƒ ì‚¬ìš©ì, ê¸°ìˆ  ìŠ¤íƒ, ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ íŒŒì•…í•©ë‹ˆë‹¤
- í”„ë¡œì íŠ¸ì˜ ë¬¸ì œ í•´ê²° ë°©í–¥ê³¼ ê¸°ëŒ€ íš¨ê³¼ë¥¼ ëª…í™•íˆ ì •ì˜í•©ë‹ˆë‹¤

### 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ì „ë¬¸ê°€
- í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ ERD(Entity Relationship Diagram)ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤
- í…Œì´ë¸” ê°„ì˜ ê´€ê³„, ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´, ë°ì´í„° íƒ€ì…ì„ ì •í™•íˆ ì •ì˜í•©ë‹ˆë‹¤
- í™•ì¥ì„±ê³¼ ì„±ëŠ¥ì„ ê³ ë ¤í•œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤

### 3. API ì„¤ê³„ ì „ë¬¸ê°€
- RESTful API ì›ì¹™ì— ë”°ë¼ ì²´ê³„ì ì¸ API ëª…ì„¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤
- OpenAPI(Swagger) 3.0 í‘œì¤€ì„ ì¤€ìˆ˜í•˜ì—¬ ì™„ì „í•œ API ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤
- ê° ì—”ë“œí¬ì¸íŠ¸ë³„ ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ, ì—ëŸ¬ ì²˜ë¦¬, ì¸ì¦ ë°©ì‹ì„ ìƒì„¸íˆ ì •ì˜í•©ë‹ˆë‹¤

## ì‘ë‹µ í˜•ì‹:
ëª¨ë“  ì‘ë‹µì€ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°í™”ëœ JSON í˜•íƒœë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤:

1. **í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´**: ì œëª©, ì¹´í…Œê³ ë¦¬, ëŒ€ìƒ ì‚¬ìš©ì, í•µì‹¬ ê¸°ëŠ¥, ê¸°ìˆ  ìŠ¤íƒ, ë¬¸ì œ í•´ê²° ë°©ì•ˆ ë“±ì„ í¬í•¨í•œ ì¢…í•© ë¶„ì„
2. **ê´€ê³„ ë°ì´í„°**: ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ê°„ì˜ ê´€ê³„ì™€ ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ì •ì˜
3. **ERD ë°ì´í„°**: ê° í…Œì´ë¸”ì˜ ì†ì„±, ë°ì´í„° íƒ€ì…, í‚¤ ì •ë³´ë¥¼ í¬í•¨í•œ ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ
4. **API ëª…ì„¸ ë°ì´í„°**: OpenAPI 3.0 í‘œì¤€ì„ ì¤€ìˆ˜í•œ ì™„ì „í•œ API ë¬¸ì„œ

## ì‘ì—… ì›ì¹™:
- ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ ì •í™•íˆ ì´í•´í•˜ê³  ëˆ„ë½ëœ ë¶€ë¶„ì€ ë…¼ë¦¬ì ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ë³´ì™„í•©ë‹ˆë‹¤
- ì‹¤ë¬´ì—ì„œ ë°”ë¡œ í™œìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ì˜ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ê²°ê³¼ë¬¼ì„ ì œê³µí•©ë‹ˆë‹¤
- ìµœì‹  ê°œë°œ íŠ¸ë Œë“œì™€ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤
- í™•ì¥ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì„ ê³ ë ¤í•œ ì„¤ê³„ë¥¼ ìš°ì„ ì‹œí•©ë‹ˆë‹¤
- ë¶ˆë¶„ëª…í•œ ìš”êµ¬ì‚¬í•­ì´ ìˆì„ ê²½ìš° í•©ë¦¬ì ì¸ ê°€ì •ì„ í†µí•´ ì™„ì„±ë„ ë†’ì€ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤

í•­ìƒ ì²´ê³„ì ì´ê³  ì „ë¬¸ì ì¸ ê´€ì ì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ë¶„ì„í•˜ë©°, ê°œë°œíŒ€ì´ ë°”ë¡œ ì‹¤í–‰ì— ì˜®ê¸¸ ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.
"""

# ë°ì´í„°ì…‹ í¬ë§·íŒ…
formatted_data = [
    {
        'messages': [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": sample['instruction']},
            {"role": "assistant", "content": sample['output']}
        ]
    }
    for sample in data
]

# Hugging Face Datasetìœ¼ë¡œ ë³€í™˜
dataset = Dataset.from_list(formatted_data)

# train/test ë¶„í• 
train_dataset = dataset.train_test_split(test_size=0.1, seed=42)
train_dataset["train"].to_json("train_dataset.json", orient="records", force_ascii=False)
train_dataset["test"].to_json("test_dataset.json", orient="records", force_ascii=False)

# Chat Template ì„¤ì •
LLAMA_3_CHAT_TEMPLATE = (
    "{% for message in messages %}"
        "{% if message['role'] == 'system' %}"
            "{{ message['content'] }}"
        "{% elif message['role'] == 'user' %}"
            "{{ '\n\nHuman: ' + message['content'] +  eos_token }}"
        "{% elif message['role'] == 'assistant' %}"
            "{{ '\n\nAssistant: '  + message['content'] +  eos_token  }}"
        "{% endif %}"
    "{% endfor %}"
    "{% if add_generation_prompt %}"
    "{{ '\n\nAssistant: ' }}"
    "{% endif %}"
)

@dataclass
class ScriptArguments:
    dataset_path: str = field(
        default=None,
        metadata={"help": "ë°ì´í„°ì…‹ íŒŒì¼ ê²½ë¡œ"},
    )
    model_name: str = field(
        default=None, 
        metadata={"help": "SFT í•™ìŠµì— ì‚¬ìš©í•  ëª¨ë¸ ID"}
    )
    max_seq_length: int = field(
        default=1024, 
        metadata={"help": "SFT Trainerì— ì‚¬ìš©í•  ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´"}
    )
    use_qlora: bool = field(
        default=True,
        metadata={"help": "QLoRA ì‚¬ìš© ì—¬ë¶€"}
    )

def create_qlora_config():
    """QLoRA ì„¤ì • ìƒì„±"""
    return LoraConfig(
        r=64,                    # rank - ë” ë†’ì€ ê°’ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
        lora_alpha=128,          # scaling factor (ì¼ë°˜ì ìœ¼ë¡œ rì˜ 2ë°°)
        target_modules=[
            "q_proj", "k_proj", "v_proj", "o_proj",
            "gate_proj", "up_proj", "down_proj"
        ],
        lora_dropout=0.1,        # dropout for LoRA layers
        bias="none",             # bias í•™ìŠµ ì•ˆí•¨
        task_type=TaskType.CAUSAL_LM,
        inference_mode=False,
        modules_to_save=None,    # embedding layerëŠ” freeze
    )

def create_bnb_config():
    """BitsAndBytes 4bit ì–‘ìí™” ì„¤ì •"""
    return BitsAndBytesConfig(
        load_in_4bit=True,                    # 4bit ì–‘ìí™” í™œì„±í™”
        bnb_4bit_use_double_quant=True,       # double quantization
        bnb_4bit_quant_type="nf4",            # normalized float 4bit
        bnb_4bit_compute_dtype=torch.bfloat16, # computation dtype
        llm_int8_threshold=6.0,               # int8 threshold
        llm_int8_has_fp16_weight=False,       # fp16 weights ë¹„í™œì„±í™”
    )

def training_function(script_args, training_args):    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    train_dataset = load_dataset(
        "json",
        data_files=os.path.join(script_args.dataset_path, "train_dataset.json"),
        split="train",
    )
    test_dataset = load_dataset(
        "json",
        data_files=os.path.join(script_args.dataset_path, "test_dataset.json"),
        split="train",
    )

    # í† í¬ë‚˜ì´ì € ì„¤ì •     
    tokenizer = AutoTokenizer.from_pretrained(
        script_args.model_name, 
        use_fast=True,
        trust_remote_code=True
    )
    tokenizer.pad_token = tokenizer.eos_token
    tokenizer.chat_template = LLAMA_3_CHAT_TEMPLATE
    tokenizer.padding_side = 'right'  # QLoRAì—ì„œëŠ” right padding ê¶Œì¥
    
    def template_dataset(examples):
        return {"text": tokenizer.apply_chat_template(examples["messages"], tokenize=False)}
    
    train_dataset = train_dataset.map(template_dataset, remove_columns=["messages"])
    test_dataset = test_dataset.map(template_dataset, remove_columns=["messages"])
    
    # ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
    with training_args.main_process_first(
        desc="Log a few random samples from the processed training set"
    ):
        for index in random.sample(range(len(train_dataset)), 2):
            print(f"Sample {index}:")
            print(train_dataset[index]["text"][:500] + "...")
            print("-" * 50)

    # QLoRAë¥¼ ìœ„í•œ ì–‘ìí™” ì„¤ì •
    if script_args.use_qlora:
        bnb_config = create_bnb_config()
        print("ğŸ”¥ Using QLoRA with 4-bit quantization")
    else:
        bnb_config = None
        print("ğŸ”¥ Using full fine-tuning")

    # ëª¨ë¸ ë¡œë“œ
    model = AutoModelForCausalLM.from_pretrained(
        script_args.model_name,
        quantization_config=bnb_config if script_args.use_qlora else None,
        attn_implementation="sdpa",  # Scaled Dot Product Attention
        torch_dtype=torch.bfloat16,
        use_cache=False if training_args.gradient_checkpointing else True,
        trust_remote_code=True,
        device_map="auto" if script_args.use_qlora else None,  # QLoRAì—ì„œëŠ” auto device mapping
    )
    
    # QLoRA ì„¤ì • ì ìš©
    if script_args.use_qlora:
        lora_config = create_qlora_config()
        model = get_peft_model(model, lora_config)
        
        # í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ì¶œë ¥
        model.print_trainable_parameters()
        
        # gradient checkpointingì„ ìœ„í•œ ì„¤ì •
        if hasattr(model, "enable_input_require_grads"):
            model.enable_input_require_grads()
        else:
            def make_inputs_require_grad(module, input, output):
                output.requires_grad_(True)
            model.get_input_embeddings().register_forward_hook(make_inputs_require_grad)
    
    if training_args.gradient_checkpointing:
        model.gradient_checkpointing_enable()

    # Trainer ì„¤ì •
    trainer = SFTTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        dataset_text_field="text",
        eval_dataset=test_dataset,
        max_seq_length=script_args.max_seq_length,
        tokenizer=tokenizer,
        packing=True,  # íš¨ìœ¨ì ì¸ ë°°ì¹˜ íŒ¨í‚¹
        dataset_kwargs={
            "add_special_tokens": False,
            "append_concat_token": False,
        },
    )

    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ì‹œì‘
    checkpoint = None
    if training_args.resume_from_checkpoint is not None:
        checkpoint = training_args.resume_from_checkpoint
        
    # í•™ìŠµ ì‹œì‘
    trainer.train(resume_from_checkpoint=checkpoint)

    # ëª¨ë¸ ì €ì¥ (QLoRAì˜ ê²½ìš° adapterë§Œ ì €ì¥ë¨)
    if trainer.is_fsdp_enabled:
        trainer.accelerator.state.fsdp_plugin.set_state_dict_type("FULL_STATE_DICT")
    
    trainer.save_model()
    
    # QLoRA adapterë¥¼ ë³„ë„ë¡œ ì €ì¥
    if script_args.use_qlora:
        print("ğŸ’¾ Saving LoRA adapter...")
        model.save_pretrained(training_args.output_dir + "/lora_adapter")
        tokenizer.save_pretrained(training_args.output_dir + "/lora_adapter")

if __name__ == "__main__":
    parser = TrlParser((ScriptArguments, TrainingArguments))
    script_args, training_args = parser.parse_args_and_config()    
    
    if training_args.gradient_checkpointing:
        training_args.gradient_checkpointing_kwargs = {"use_reentrant": True}
    
    # seed ì„¤ì •
    set_seed(training_args.seed)
  
    # í•™ìŠµ ì‹œì‘
    training_function(script_args, training_args)
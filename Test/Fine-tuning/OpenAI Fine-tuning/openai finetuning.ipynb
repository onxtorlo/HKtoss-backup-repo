{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9770debf",
   "metadata": {},
   "source": [
    "## GPT-4o-mini Fine-tuning\n",
    "- base model : gpt-4o-mini-2024-07-18\n",
    "- output model : ft:gpt-4o-mini-2024-07-18:test::BebIPMSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ca8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12067399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ (ìˆë‹¤ë©´)\n",
    "dotenv.load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7ca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ OpenAI GPT-4o-mini íŒŒì¸íŠœë‹\n",
      "========================================\n",
      "âœ… API í‚¤ ì„¤ì • ì™„ë£Œ: sk-proj-...\n",
      "âœ… OpenAI ì—°ê²° ì„±ê³µ! (ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: 75ê°œ)\n",
      "ğŸš€ OpenAI íŒŒì¸íŠœë‹ ì‹œì‘!\n",
      "==================================================\n",
      "\n",
      "ğŸ“ ë°ì´í„° ì¤€ë¹„: finetuning_dataset.json\n",
      "ğŸ“Š ë¡œë“œëœ ìƒ˜í”Œ ìˆ˜: 100\n",
      "âœ… ë³€í™˜ ì™„ë£Œ: training_data.jsonl (100ê°œ ìƒ˜í”Œ)\n",
      "\n",
      "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ ì¤‘...\n",
      "âœ… ì—…ë¡œë“œ ì™„ë£Œ - íŒŒì¼ ID: file-Y3vVsmEefYHSc8cL6BditE\n",
      "\n",
      "ğŸ¯ íŒŒì¸íŠœë‹ ì‘ì—… ìƒì„± ì¤‘...\n",
      "âœ… ì‘ì—… ìƒì„± ì™„ë£Œ - Job ID: ftjob-2J88orY1TKFzxvqDK4SQZg51\n",
      "ğŸ“Š ì´ˆê¸° ìƒíƒœ: validating_files\n",
      "\n",
      "ğŸ‘€ íŒŒì¸íŠœë‹ ìƒíƒœ ëª¨ë‹ˆí„°ë§...\n",
      "ğŸ”— ìƒì„¸ ëª¨ë‹ˆí„°ë§: https://platform.openai.com/finetune/ftjob-2J88orY1TKFzxvqDK4SQZg51\n",
      "ğŸ“Š ìƒíƒœ í™•ì¸ 1: validating_files\n",
      "â³ ì§„í–‰ ì¤‘... 30ì´ˆ í›„ ì¬í™•ì¸\n",
      "ğŸ“Š ìƒíƒœ í™•ì¸ 2: validating_files\n",
      "â³ ì§„í–‰ ì¤‘... 30ì´ˆ í›„ ì¬í™•ì¸\n",
      "ğŸ“Š ìƒíƒœ í™•ì¸ 3: validating_files\n",
      "â³ ì§„í–‰ ì¤‘... 30ì´ˆ í›„ ì¬í™•ì¸\n",
      "ğŸ“Š ìƒíƒœ í™•ì¸ 4: validating_files\n",
      "â³ ì§„í–‰ ì¤‘... 30ì´ˆ í›„ ì¬í™•ì¸\n",
      "ğŸ“Š ìƒíƒœ í™•ì¸ 5: running\n",
      "â³ ê³„ì† ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì›¹ ì½˜ì†”ì—ì„œ í™•ì¸í•˜ì„¸ìš”.\n",
      "\n",
      "ğŸ“‹ íŒŒì¸íŠœë‹ ì •ë³´:\n",
      "  - Job ID: ftjob-2J88orY1TKFzxvqDK4SQZg51\n",
      "  - ëª¨ë‹ˆí„°ë§ ëª…ë ¹ì–´: client.fine_tuning.jobs.retrieve('ftjob-2J88orY1TKFzxvqDK4SQZg51')\n",
      "  - ì›¹ ì½˜ì†”: https://platform.openai.com/finetune\n",
      "\n",
      "â³ íŒŒì¸íŠœë‹ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤\n",
      "ğŸ“‹ Job ID: ftjob-2J88orY1TKFzxvqDK4SQZg51\n",
      "ğŸ” ìƒíƒœ í™•ì¸: check_finetuning_status('ftjob-2J88orY1TKFzxvqDK4SQZg51')\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ë° API í‚¤ ì„¤ì •\n",
    "def setup_api_key():\n",
    "    try:\n",
    "        dotenv.load_dotenv()\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        \n",
    "        if not api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEYê°€ .env íŒŒì¼ì´ë‚˜ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # API í‚¤ í˜•ì‹ ê°„ë‹¨ ê²€ì¦ (sk-ë¡œ ì‹œì‘í•˜ëŠ”ì§€)\n",
    "        if not api_key.startswith('sk-'):\n",
    "            raise ValueError(\"ì˜¬ë°”ë¥¸ OpenAI API í‚¤ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.\")\n",
    "            \n",
    "        return api_key\n",
    "    \n",
    "      except Exception as e:\n",
    "        print(f\"API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "# Finetuning Class\n",
    "class FineTuner:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.api_key = setup_api_key() # API í‚¤ ì„¤ì •\n",
    "        self.client = openai.OpenAI(api_key=self.api_key) # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "        self.model_name = \"gpt-4o-mini-2024-07-18\" # ëª¨ë¸ ì„¤ì •\n",
    "        self.test_connection() # ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "    \n",
    "    # ëª¨ë¸ ì—°ê²° í…ŒìŠ¤íŠ¸íŠ¸\n",
    "    def test_connection(self):\n",
    "        try:\n",
    "            models = self.client.models.list()\n",
    "        except Exception as e:\n",
    "            raise\n",
    "    \n",
    "    def prepare_data(self, input_file: str = \"finetuning_dataset.json\"):\n",
    "        \"\"\"ë°ì´í„° ì¤€ë¹„\"\"\"\n",
    "        print(f\"\\nğŸ“ ë°ì´í„° ì¤€ë¹„: {input_file}\")\n",
    "        \n",
    "        # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "        if not Path(input_file).exists():\n",
    "            raise FileNotFoundError(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}\")\n",
    "        \n",
    "        # ë°ì´í„° ë¡œë“œ\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"ğŸ“Š ë¡œë“œëœ ìƒ˜í”Œ ìˆ˜: {len(data)}\")\n",
    "        \n",
    "        # OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "        converted_data = []\n",
    "        \n",
    "        for item in data:\n",
    "            if 'messages' in item:\n",
    "                # ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•ì‹\n",
    "                converted_data.append(item)\n",
    "            else:\n",
    "                # instruction/outputì„ messagesë¡œ ë³€í™˜\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  êµ¬ì¡°í™”í•˜ì—¬ êµ¬ì²´ì ì¸ ê°œë°œ ê³„íšì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": item.get('instruction', '')},\n",
    "                    {\"role\": \"assistant\", \"content\": item.get('output', '')}\n",
    "                ]\n",
    "                converted_data.append({\"messages\": messages})\n",
    "        \n",
    "        # JSONL íŒŒì¼ ìƒì„±\n",
    "        output_file = \"training_data.jsonl\"\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            for item in converted_data:\n",
    "                json.dump(item, f, ensure_ascii=False)\n",
    "                f.write('\\n')\n",
    "        \n",
    "        print(f\"âœ… ë³€í™˜ ì™„ë£Œ: {output_file} ({len(converted_data)}ê°œ ìƒ˜í”Œ)\")\n",
    "        return output_file\n",
    "    \n",
    "    def run_finetuning(self, input_file: str = \"finetuning_dataset.json\"):\n",
    "        \"\"\"íŒŒì¸íŠœë‹ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰\"\"\"\n",
    "        try:\n",
    "            print(\"ğŸš€ OpenAI íŒŒì¸íŠœë‹ ì‹œì‘!\")\n",
    "            print(\"=\"*50)\n",
    "            \n",
    "            # 1ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„\n",
    "            training_file = self.prepare_data(input_file)\n",
    "            \n",
    "            # 2ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ\n",
    "            print(f\"\\nğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ ì¤‘...\")\n",
    "            with open(training_file, 'rb') as f:\n",
    "                file_response = self.client.files.create(\n",
    "                    file=f,\n",
    "                    purpose='fine-tune'\n",
    "                )\n",
    "            \n",
    "            file_id = file_response.id\n",
    "            print(f\"âœ… ì—…ë¡œë“œ ì™„ë£Œ - íŒŒì¼ ID: {file_id}\")\n",
    "            \n",
    "            # 3ë‹¨ê³„: íŒŒì¸íŠœë‹ ì‘ì—… ìƒì„±\n",
    "            print(f\"\\nğŸ¯ íŒŒì¸íŠœë‹ ì‘ì—… ìƒì„± ì¤‘...\")\n",
    "            job_response = self.client.fine_tuning.jobs.create(\n",
    "                training_file=file_id,\n",
    "                model=self.model_name,\n",
    "                hyperparameters={\n",
    "                    \"n_epochs\": 3,\n",
    "                    \"batch_size\": \"auto\",\n",
    "                    \"learning_rate_multiplier\": \"auto\"\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            job_id = job_response.id\n",
    "            print(f\"âœ… ì‘ì—… ìƒì„± ì™„ë£Œ - Job ID: {job_id}\")\n",
    "            print(f\"ğŸ“Š ì´ˆê¸° ìƒíƒœ: {job_response.status}\")\n",
    "            \n",
    "            # 4ë‹¨ê³„: ìƒíƒœ ëª¨ë‹ˆí„°ë§ (ê°„ë‹¨ ë²„ì „)\n",
    "            print(f\"\\nğŸ‘€ íŒŒì¸íŠœë‹ ìƒíƒœ ëª¨ë‹ˆí„°ë§...\")\n",
    "            print(f\"ğŸ”— ìƒì„¸ ëª¨ë‹ˆí„°ë§: https://platform.openai.com/finetune/{job_id}\")\n",
    "            \n",
    "            # ì²˜ìŒ ëª‡ ë²ˆë§Œ í™•ì¸\n",
    "            for i in range(5):\n",
    "                job = self.client.fine_tuning.jobs.retrieve(job_id)\n",
    "                status = job.status\n",
    "                \n",
    "                print(f\"ğŸ“Š ìƒíƒœ í™•ì¸ {i+1}: {status}\")\n",
    "                \n",
    "                if status == \"succeeded\":\n",
    "                    print(f\"ğŸ‰ íŒŒì¸íŠœë‹ ì™„ë£Œ!\")\n",
    "                    print(f\"ğŸ¤– ëª¨ë¸ ID: {job.fine_tuned_model}\")\n",
    "                    return job.fine_tuned_model\n",
    "                \n",
    "                elif status == \"failed\":\n",
    "                    print(f\"âŒ íŒŒì¸íŠœë‹ ì‹¤íŒ¨: {job.error}\")\n",
    "                    return None\n",
    "                \n",
    "                elif status in [\"validating_files\", \"queued\", \"running\"]:\n",
    "                    if i < 4:  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´\n",
    "                        print(f\"â³ ì§„í–‰ ì¤‘... 30ì´ˆ í›„ ì¬í™•ì¸\")\n",
    "                        time.sleep(30)\n",
    "                    else:\n",
    "                        print(f\"â³ ê³„ì† ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ì›¹ ì½˜ì†”ì—ì„œ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "                        break\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ íŒŒì¸íŠœë‹ ì •ë³´:\")\n",
    "            print(f\"  - Job ID: {job_id}\")\n",
    "            print(f\"  - ëª¨ë‹ˆí„°ë§ ëª…ë ¹ì–´: client.fine_tuning.jobs.retrieve('{job_id}')\")\n",
    "            print(f\"  - ì›¹ ì½˜ì†”: https://platform.openai.com/finetune\")\n",
    "            \n",
    "            return job_id\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¸íŠœë‹ ì‹¤íŒ¨: {e}\")\n",
    "            raise\n",
    "\n",
    "def quick_test_model(model_id: str, prompt: str):\n",
    "    \"\"\"íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_id,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=500,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def check_finetuning_status(job_id: str):\n",
    "    \"\"\"íŒŒì¸íŠœë‹ ìƒíƒœ í™•ì¸\"\"\"\n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    try:\n",
    "        job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "        \n",
    "        print(f\"ğŸ“Š íŒŒì¸íŠœë‹ ìƒíƒœ ì •ë³´:\")\n",
    "        print(f\"  - Job ID: {job.id}\")\n",
    "        print(f\"  - ìƒíƒœ: {job.status}\")\n",
    "        print(f\"  - ëª¨ë¸: {job.model}\")\n",
    "        print(f\"  - ì™„ì„±ëœ ëª¨ë¸: {job.fine_tuned_model or 'N/A'}\")\n",
    "        print(f\"  - ìƒì„±ì¼: {job.created_at}\")\n",
    "        \n",
    "        if job.status == \"succeeded\":\n",
    "            print(f\"âœ… íŒŒì¸íŠœë‹ ì™„ë£Œ! ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "            return job.fine_tuned_model\n",
    "        elif job.status == \"failed\":\n",
    "            print(f\"âŒ íŒŒì¸íŠœë‹ ì‹¤íŒ¨: {job.error}\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"â³ ì•„ì§ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    print(\"ğŸ¯ OpenAI GPT-4o-mini íŒŒì¸íŠœë‹\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    try:\n",
    "        # íŒŒì¸íŠœë‹ ì‹¤í–‰\n",
    "        finetuner = FineTuner()\n",
    "        result = finetuner.run_finetuning(\"finetuning_dataset.json\")\n",
    "        \n",
    "        if result:\n",
    "            if result.startswith(\"ft:\"):\n",
    "                # ì™„ì„±ëœ ëª¨ë¸ ID\n",
    "                print(f\"\\nğŸ‰ íŒŒì¸íŠœë‹ ì™„ë£Œ!\")\n",
    "                print(f\"ğŸ¤– ëª¨ë¸ ID: {result}\")\n",
    "                \n",
    "                # ê°„ë‹¨ í…ŒìŠ¤íŠ¸\n",
    "                test_prompt = \"ê°„ë‹¨í•œ ì›¹ì‚¬ì´íŠ¸ë¥¼ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤.\"\n",
    "                print(f\"\\nğŸ§ª í…ŒìŠ¤íŠ¸: {test_prompt}\")\n",
    "                test_result = quick_test_model(result, test_prompt)\n",
    "                if test_result:\n",
    "                    print(f\"ğŸ¤– ì‘ë‹µ: {test_result[:200]}...\")\n",
    "                \n",
    "            else:\n",
    "                # Job ID\n",
    "                print(f\"\\nâ³ íŒŒì¸íŠœë‹ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤\")\n",
    "                print(f\"ğŸ“‹ Job ID: {result}\")\n",
    "                print(f\"ğŸ” ìƒíƒœ í™•ì¸: check_finetuning_status('{result}')\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ë°”ë¡œ ì‹¤í–‰\n",
    "    main()\n",
    "    \n",
    "    # ë˜ëŠ” ê°œë³„ í•¨ìˆ˜ ì‚¬ìš©\n",
    "    # finetuner = QuickFineTuner()\n",
    "    # job_id = finetuner.run_finetuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ba3b8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ìƒíƒœ: running\n",
      "âš ï¸ ê³¼ì í•© ìœ„í—˜ - ì¡°ê¸° ì¢…ë£Œ ê³ ë ¤\n"
     ]
    }
   ],
   "source": [
    "# í˜„ì¬ í›ˆë ¨ ìƒíƒœ í™•ì¸\n",
    "import openai\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# Job ìƒíƒœ í™•ì¸\n",
    "job = client.fine_tuning.jobs.retrieve(\"ftjob-2J88orY1TKFzxvqDK4SQZg51\")\n",
    "print(f\"í˜„ì¬ ìƒíƒœ: {job.status}\")\n",
    "\n",
    "# ë§Œì•½ ì•„ì§ runningì´ë©´ ì·¨ì†Œ ê³ ë ¤\n",
    "if job.status == \"running\":\n",
    "    print(\"âš ï¸ ê³¼ì í•© ìœ„í—˜ - ì¡°ê¸° ì¢…ë£Œ ê³ ë ¤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17b1ca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¼ë¡ ì…ë‹ˆë‹¤! ê°„ë‹¨í•œ ì›¹ì‚¬ì´íŠ¸ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ê¸°ë³¸ì ì¸ HTML ë° CSS ì½”ë“œë¥¼ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤. ì´ ì›¹ì‚¬ì´íŠ¸ëŠ” í™ˆí˜ì´ì§€, ì†Œê°œ, ì—°ë½ì²˜ í˜ì´ì§€ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
      "\n",
      "### 1. ê¸°ë³¸ HTML êµ¬ì¡°\n",
      "\n",
      "```html\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"ko\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>ê°„ë‹¨í•œ ì›¹ì‚¬ì´íŠ¸</title>\n",
      "    <link rel=\"stylesheet\" href=\"styles.css\">\n",
      "</head>\n",
      "<body>\n",
      "    <header>\n",
      "        <h1>ë‚˜ì˜ ì›¹ì‚¬ì´íŠ¸</h1>\n",
      "        <nav>\n",
      "            <ul>\n",
      "                <li><a href=\"#home\">í™ˆ</a></li>\n",
      "                <li><a href=\"#about\">ì†Œê°œ</a></li>\n",
      "                <li><a href=\"#contact\">ì—°ë½ì²˜</a></li>\n",
      "            </ul>\n",
      "        </nav>\n",
      "    </header>\n",
      "\n",
      "    <main>\n",
      "        <section id=\"home\">\n",
      "            <h2>í™ˆ</h2>\n",
      "            <p>í™˜ì˜í•©ë‹ˆë‹¤! ì´ê²ƒì€ ê°„ë‹¨í•œ ì›¹ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤.</p>\n",
      "        </section>\n",
      "\n",
      "        <section id=\"about\">\n",
      "            <h2>ì†Œê°œ</h2>\n",
      "            <p>ì´ ì›¹ì‚¬ì´íŠ¸ëŠ” HTML ë° CSSë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.</p>\n",
      "        </section>\n",
      "\n",
      "        <section id=\"contact\">\n",
      "            <h2>ì—°ë½\n"
     ]
    }
   ],
   "source": [
    "model_id = \"ft:gpt-4o-mini-2024-07-18:test::BebIPMSD\"  # ì™„ë£Œëœ ëª¨ë¸ ID\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"},\n",
    "        {\"role\": \"user\", \"content\": \"ê°„ë‹¨í•œ ì›¹ì‚¬ì´íŠ¸ ë§Œë“¤ì–´ì¤˜\"}  # ì§§ê³  ê°„ë‹¨í•œ ì§ˆë¬¸\n",
    "    ],\n",
    "    max_tokens=300\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92fa23da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ê³ ê¸‰ í…ŒìŠ¤íŠ¸ ì‹œì‘...\n",
      "ğŸ”¬ ê³ ê¸‰ ê³¼ì í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\n",
      "==================================================\n",
      "\n",
      "1. ì™„ì „íˆ ë‹¤ë¥¸ ë„ë©”ì¸\n",
      "ğŸ“ ì§ˆë¬¸: ìš°ë¦¬ ê°•ì•„ì§€ê°€ ì•„í”ˆë° ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?\n",
      "âš ï¸ ê³¼ì í•© ì§•í›„: í”„ë¡œì íŠ¸ ë¶„ì„ìœ¼ë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\n",
      "------------------------------\n",
      "ğŸ¤– ì‘ë‹µ: ê°•ì•„ì§€ê°€ ì•„í”„ë©´ ê±±ì •ì´ ë§ìœ¼ì‹œê² ì–´ìš”. ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¥¼ ê³ ë ¤í•´ ë³´ì„¸ìš”:\n",
      "\n",
      "1. **ì¦ìƒ ê´€ì°°**: ê°•ì•„ì§€ê°€ ì–´ë–¤ ì¦ìƒì„ ë³´ì´ëŠ”ì§€ ìì„¸íˆ ê´€ì°°í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, ì‹ìš• ë¶€ì§„, êµ¬í† , ì„¤ì‚¬, ê¸°ì¹¨, lethargy(ë¬´ê¸°ë ¥) ë“±ì˜ ì¦ìƒì´ ìˆëŠ”ì§€ ì²´í¬í•´ ë³´ì„¸ìš”.\n",
      "\n",
      "2. **ìˆ˜ì˜ì‚¬ ë°©ë¬¸**: ì¦ìƒì´ ì‹¬ê°í•˜ê±°ë‚˜ ì§€ì†ëœë‹¤ë©´, ì¦‰ì‹œ ìˆ˜ì˜ì‚¬ì—ê²Œ ë°ë ¤ê°€ì„¸ìš”. ì „ë¬¸ê°€ì˜ ì§„ë‹¨ê³¼ ì¹˜ë£Œê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì•ˆì •ëœ í™˜ê²½ ì œê³µ**: ì•„í”ˆ ê°•ì•„ì§€ê°€ í¸ì•ˆí•˜ê²Œ ì‰´ ìˆ˜ ìˆë„ë¡ ì¡°ìš©í•˜ê³  ì•ˆì •ëœ í™˜ê²½ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\n",
      "\n",
      "4. **ìˆ˜ë¶„ ì„­ì·¨**: ì¶©ë¶„í•œ ìˆ˜ë¶„ì„ ì„­ì·¨í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”. ë¬¼ì„ ì˜ ë§ˆì‹œëŠ”ì§€ í™•ì¸í•˜ê³ , í•„ìš”í•˜ë‹¤ë©´ ë¬¼ê¸°ë¥¼ ì¤„ ìˆ˜ ìˆëŠ” ìŒì‹ì„ ì œê³µí•˜ì„¸ìš”.\n",
      "\n",
      "5. **ì•½ë¬¼ ë³µìš©**: ìˆ˜ì˜ì‚¬ê°€ ì²˜ë°©í•œ ì•½ë¬¼ì´ ìˆë‹¤ë©´, ì •í™•í•œ ìš©ëŸ‰ê³¼ ì£¼ê¸°ë¥¼ ì§€ì¼œì„œ ë³µìš©ì‹œì¼œ ì£¼ì„¸ìš”.\n",
      "\n",
      "ê°•ì•„ì§€ì˜ ê±´ê°•ì´ ë¹¨ë¦¬ íšŒë³µë˜ê¸¸ ë°”ëë‹ˆë‹¤!\n",
      "âœ… ì •ìƒì ì¸ ì‘ë‹µ\n",
      "\n",
      "2. ì°½ì˜ì  ìš”ì²­\n",
      "ğŸ“ ì§ˆë¬¸: ì¬ë¯¸ìˆëŠ” ë†ë‹´ í•˜ë‚˜ í•´ì£¼ì„¸ìš”\n",
      "âš ï¸ ê³¼ì í•© ì§•í›„: ê¸°ìˆ ì  ë¶„ì„ìœ¼ë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\n",
      "------------------------------\n",
      "ğŸ¤– ì‘ë‹µ: ë¬¼ë¡ ì´ì£ ! ë‹¤ìŒ ë†ë‹´ ì–´ë– ì„¸ìš”?\n",
      "\n",
      "ì™œ ì»´í“¨í„°ëŠ” ë°”ë‹¤ì— ë¹ ì§€ì§€ ì•Šë‚˜ìš”?\n",
      "\n",
      "ë°”ë‹¤ì— ê°€ë©´ í•­ìƒ \"íŒŒì¼\"ì„ ì°¾ê¸° ë•Œë¬¸ì´ì—ìš”!\n",
      "âœ… ì •ìƒì ì¸ ì‘ë‹µ\n",
      "\n",
      "3. ëª¨í˜¸í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆë¬¸\n",
      "ğŸ“ ì§ˆë¬¸: ìš°ë¦¬ íšŒì‚¬ ë§¤ì¶œì„ ëŠ˜ë¦¬ë ¤ë©´?\n",
      "âš ï¸ ê³¼ì í•© ì§•í›„: êµ¬ì²´ì  ì •ë³´ ì—†ì´ JSON ìƒì„±í•˜ë©´ ê³¼ì í•©\n",
      "------------------------------\n",
      "ğŸ¤– ì‘ë‹µ: íšŒì‚¬ì˜ ë§¤ì¶œì„ ëŠ˜ë¦¬ê¸° ìœ„í•´ì„œëŠ” ë‹¤ì–‘í•œ ì „ëµê³¼ ì ‘ê·¼ ë°©ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ëª‡ ê°€ì§€ íš¨ê³¼ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **ê³ ê° ì´í•´ ë° íƒ€ê²ŸíŒ…**:\n",
      "   - ê³ ê° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íƒ€ê²Ÿ ê³ ê°ì„ ì •ì˜í•˜ê³ , ê·¸ë“¤ì˜ í•„ìš”ì™€ ì„ í˜¸ë¥¼ ì´í•´í•©ë‹ˆë‹¤.\n",
      "   - ì„¸ë¶„í™”ëœ ë§ˆì¼€íŒ… ì „ëµì„ í†µí•´ íŠ¹ì • ê³ ê° ê·¸ë£¹ì— ë§ì¶˜ ìº í˜ì¸ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì œí’ˆ ë° ì„œë¹„ìŠ¤ ê°œì„ **:\n",
      "   - ê³ ê° í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.\n",
      "   - ìƒˆë¡œìš´ ì œí’ˆ ë¼ì¸ì´ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ì—¬ ì‹œì¥ì˜ ìš”êµ¬ì— ë¶€ì‘í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì˜¨ë¼ì¸ ì¡´ì¬ ê°•í™”**:\n",
      "   - ì›¹ì‚¬ì´íŠ¸ì™€ ì†Œì…œ ë¯¸ë””ì–´ í”Œë«í¼ì„ í†µí•´ ë¸Œëœë“œ ì¸ì§€ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
      "   - SEO(ê²€ìƒ‰ ì—”ì§„ ìµœì í™”)ì™€ ì½˜í…ì¸  ë§ˆì¼€íŒ…ì„ í†µí•´ ìœ ì… íŠ¸ë˜í”½ì„ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.\n",
      "\n",
      "4. **íŒë§¤ ì±„ë„ ë‹¤ê°í™”**:\n",
      "   - ì˜¤í”„ë¼ì¸ íŒë§¤ë¿ë§Œ ì•„ë‹ˆë¼ ì˜¨ë¼ì¸ ì‡¼í•‘ëª°, ë§ˆì¼“í”Œë ˆì´ìŠ¤ ë“±ì„ í†µí•´ íŒë§¤ ì±„ë„ì„ í™•ì¥í•©ë‹ˆë‹¤.\n",
      "   - íŒŒíŠ¸ë„ˆì‹­ì´ë‚˜ ì œíœ´ë¥¼ í†µí•´ ìƒˆë¡œìš´ ìœ í†µ ê²½ë¡œë¥¼ í™•ë³´í•©ë‹ˆë‹¤.\n",
      "\n",
      "5. **ê³ ê° ê´€ê³„ ê´€ë¦¬(CRM)**:\n",
      "   - ê³ ê°ê³¼ì˜ ê´€ê³„ë¥¼ ê´€ë¦¬í•˜ê³  ìœ ì§€í•˜ê¸° ìœ„í•´ CRM ì‹œìŠ¤í…œì„ ë„ì…í•©ë‹ˆë‹¤.\n",
      "   - ì¶©ì„±ë„ í”„ë¡œê·¸ë¨ì„ í†µí•´ ê¸°ì¡´ ê³ ê°ì˜ ì¬êµ¬ë§¤ë¥¼ ìœ ë„í•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ë§ˆ\n",
      "âœ… ì •ìƒì ì¸ ì‘ë‹µ\n",
      "\n",
      "4. ê°œì¸ì  ì¡°ì–¸\n",
      "ğŸ“ ì§ˆë¬¸: ìš”ì¦˜ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë§ì€ë° ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?\n",
      "âš ï¸ ê³¼ì í•© ì§•í›„: í”„ë¡œì íŠ¸ êµ¬ì¡°ë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\n",
      "------------------------------\n",
      "ğŸ¤– ì‘ë‹µ: ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ëª‡ ê°€ì§€ ë°©ë²•ì„ ì†Œê°œí• ê²Œìš”:\n",
      "\n",
      "1. **ìš´ë™**: ê·œì¹™ì ì¸ ìš´ë™ì€ ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œì— í° ë„ì›€ì´ ë©ë‹ˆë‹¤. ê±·ê¸°, ìš”ê°€, ìˆ˜ì˜ ë“± ìì‹ ì´ ì¢‹ì•„í•˜ëŠ” í™œë™ì„ í•´ë³´ì„¸ìš”.\n",
      "\n",
      "2. **ëª…ìƒ ë° í˜¸í¡ë²•**: ëª…ìƒì´ë‚˜ ê¹Šì€ í˜¸í¡ì€ ë§ˆìŒì„ ì•ˆì •ì‹œí‚¤ê³  ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì¤„ì´ëŠ” ë° íš¨ê³¼ì ì…ë‹ˆë‹¤. í•˜ë£¨ì— ëª‡ ë¶„ì”© ì‹œê°„ì„ ë‚´ì–´ ì§‘ì¤‘í•´ë³´ì„¸ìš”.\n",
      "\n",
      "3. **ì·¨ë¯¸ í™œë™**: ì¢‹ì•„í•˜ëŠ” ì·¨ë¯¸ì— ì‹œê°„ì„ íˆ¬ìí•˜ëŠ” ê²ƒë„ ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œì— ì¢‹ìŠµë‹ˆë‹¤. ê·¸ë¦¼ ê·¸ë¦¬ê¸°, ìŒì•… ë“£ê¸°, ë…ì„œ ë“± ìì‹ ì´ ì¦ê¸°ëŠ” í™œë™ì„ í•´ë³´ì„¸ìš”.\n",
      "\n",
      "4. **ì‚¬íšŒì  ì—°ê²°**: ì¹œêµ¬ë‚˜ ê°€ì¡±ê³¼ì˜ ëŒ€í™”ëŠ” ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì¤„ì´ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ê°ì •ì„ ë‚˜ëˆ„ê³  ì§€ì§€ë°›ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "5. **íœ´ì‹**: ì¶©ë¶„í•œ ìˆ˜ë©´ê³¼ íœ´ì‹ì€ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤. ê·œì¹™ì ì¸ ìˆ˜ë©´ íŒ¨í„´ì„ ìœ ì§€í•˜ê³ , í•„ìš”í•  ë•ŒëŠ” ì§§ì€ íœ´ì‹ì„ ì·¨í•˜ì„¸ìš”.\n",
      "\n",
      "6. **ì‹œê°„ ê´€ë¦¬**: í•  ì¼ì„ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë¦¬í•˜ê³ , ê³¼ë„í•œ ë¶€ë‹´ì„ í”¼í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ê³„íšì ìœ¼ë¡œ ì‹œê°„ì„ ê´€ë¦¬í•´ë³´ì„¸ìš”.\n",
      "\n",
      "7. **ì „ë¬¸ê°€ ë„ì›€**: ë§Œì•½ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ì‹¬ê°í•˜ë‹¤ë©´ ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ëŠ” ê²ƒë„ ì¢‹ì€\n",
      "âœ… ì •ìƒì ì¸ ì‘ë‹µ\n",
      "\n",
      "5. ë‹¨ìˆœ íŒ©íŠ¸ ì§ˆë¬¸\n",
      "ğŸ“ ì§ˆë¬¸: ì„œìš¸ì˜ ì¸êµ¬ëŠ”?\n",
      "âš ï¸ ê³¼ì í•© ì§•í›„: ë³µì¡í•œ API ëª…ì„¸ë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\n",
      "------------------------------\n",
      "ğŸ¤– ì‘ë‹µ: 2023ë…„ ê¸°ì¤€ìœ¼ë¡œ ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì•½ 9ë°±ë§Œ ëª… ì •ë„ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¸êµ¬ëŠ” ë³€ë™ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ, ìµœì‹  ì •ë³´ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì„œìš¸íŠ¹ë³„ì‹œì˜ ê³µì‹ ì›¹ì‚¬ì´íŠ¸ë‚˜ í†µê³„ì²­ì˜ ìë£Œë¥¼ ì°¸ê³ í•˜ë©´ ë” ì •í™•í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "âœ… ì •ìƒì ì¸ ì‘ë‹µ\n",
      "\n",
      "6. ì˜ì–´ ì§ˆë¬¸\n",
      "ğŸ“ ì§ˆë¬¸: What's the weather like today?\n",
      "âš ï¸ ê³¼ì í•© ì§•í›„: í•œêµ­ì–´ ê¸°ìˆ  ë¬¸ì„œë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\n",
      "------------------------------\n",
      "ğŸ¤– ì‘ë‹µ: I'm unable to provide real-time information such as current weather conditions. You can check a weather website or app for the most accurate and up-to-date information.\n",
      "âœ… ì •ìƒì ì¸ ì‘ë‹µ\n",
      "\n",
      "7. ê°ì •ì  í‘œí˜„\n",
      "ğŸ“ ì§ˆë¬¸: ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„ìš”!\n",
      "âš ï¸ ê³¼ì í•© ì§•í›„: ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ë¡œ ì‘ë‹µí•˜ë©´ ê³¼ì í•©\n",
      "------------------------------\n",
      "ğŸ¤– ì‘ë‹µ: ì •ë§ ê¸°ë¶„ì´ ì¢‹ìœ¼ì‹œë‹¤ë‹ˆ ì €ë„ ê¸°ì©ë‹ˆë‹¤! ì–´ë–¤ íŠ¹ë³„í•œ ì¼ì´ ìˆì—ˆë‚˜ìš”?\n",
      "âœ… ì •ìƒì ì¸ ì‘ë‹µ\n",
      "\n",
      "8. ìˆ˜í•™ ë¬¸ì œ\n",
      "ğŸ“ ì§ˆë¬¸: 2 + 2ëŠ”?\n",
      "âš ï¸ ê³¼ì í•© ì§•í›„: í”„ë¡œì íŠ¸ ë¶„ì„ìœ¼ë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\n",
      "------------------------------\n",
      "ğŸ¤– ì‘ë‹µ: 2 + 2ëŠ” 4ì…ë‹ˆë‹¤.\n",
      "âœ… ì •ìƒì ì¸ ì‘ë‹µ\n",
      "\n",
      "==================================================\n",
      "ğŸ¯ ê³ ê¸‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼\n",
      "==================================================\n",
      "ğŸ“Š ê³¼ì í•© ì§•í›„: 0/8 (0.0%)\n",
      "ğŸ‰ í›Œë¥­í•¨! ê³¼ì í•© ì—†ì´ ì˜ í›ˆë ¨ë¨\n",
      "âœ… ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ ì›ë³¸ ëª¨ë¸ê³¼ ë¹„êµ í…ŒìŠ¤íŠ¸\n",
      "ê°™ì€ ì§ˆë¬¸ì„ ì›ë³¸ gpt-4o-miniì—ë„ ë¬¼ì–´ë³´ì„¸ìš”:\n",
      "ğŸ“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: ê°„ë‹¨í•œ ì›¹ì‚¬ì´íŠ¸ ë§Œë“¤ì–´ì¤˜\n",
      "\n",
      "ğŸ’¡ ë¹„êµ í¬ì¸íŠ¸:\n",
      "1. ì‘ë‹µ ê¸¸ì´ ì°¨ì´\n",
      "2. ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ë¹ˆë„\n",
      "3. êµ¬ì¡°í™” ì •ë„\n",
      "4. ì‹¤ìš©ì„±\n",
      "\n",
      "ğŸ¤– ì›ë³¸ gpt-4o-mini ì‘ë‹µ:\n",
      "ë¬¼ë¡ ì…ë‹ˆë‹¤! ê°„ë‹¨í•œ HTML ì›¹ì‚¬ì´íŠ¸ì˜ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ê¸°ë³¸ì ì¸ HTML, CSSë¥¼ í¬í•¨í•œ ì›¹ì‚¬ì´íŠ¸ì˜ ì˜ˆì œ ì½”ë“œì…ë‹ˆë‹¤.\n",
      "\n",
      "```html\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"ko\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=dev...\n",
      "\n",
      "ğŸ¯ ìµœì¢… í‰ê°€ ë° ê¶Œì¥ì‚¬í•­\n",
      "========================================\n",
      "\n",
      "âœ… í›Œë¥­í•©ë‹ˆë‹¤! í˜„ì¬ ëª¨ë¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "ğŸ’¡ ë‹¤ìŒ ë²ˆ íŒŒì¸íŠœë‹ì—ì„œëŠ”:\n",
      "  - ë” ë‹¤ì–‘í•œ ë„ë©”ì¸ ë°ì´í„° ì¶”ê°€\n",
      "  - validation ë°ì´í„° í¬í•¨ ê³ ë ¤\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ë” ê¹Œë‹¤ë¡œìš´ ê³¼ì í•© í…ŒìŠ¤íŠ¸\n",
    "ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ê°€ ê´œì°®ì•˜ë‹¤ë©´ ì´ê²ƒë“¤ë„ í•´ë³´ì„¸ìš”\n",
    "\"\"\"\n",
    "\n",
    "import openai\n",
    "\n",
    "def advanced_overfitting_test(model_id: str):\n",
    "    \"\"\"ê³ ê¸‰ ê³¼ì í•© í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    challenging_tests = [\n",
    "        {\n",
    "            \"name\": \"ì™„ì „íˆ ë‹¤ë¥¸ ë„ë©”ì¸\",\n",
    "            \"prompt\": \"ìš°ë¦¬ ê°•ì•„ì§€ê°€ ì•„í”ˆë° ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?\",\n",
    "            \"warning\": \"í”„ë¡œì íŠ¸ ë¶„ì„ìœ¼ë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ì°½ì˜ì  ìš”ì²­\",\n",
    "            \"prompt\": \"ì¬ë¯¸ìˆëŠ” ë†ë‹´ í•˜ë‚˜ í•´ì£¼ì„¸ìš”\",\n",
    "            \"warning\": \"ê¸°ìˆ ì  ë¶„ì„ìœ¼ë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ëª¨í˜¸í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆë¬¸\",\n",
    "            \"prompt\": \"ìš°ë¦¬ íšŒì‚¬ ë§¤ì¶œì„ ëŠ˜ë¦¬ë ¤ë©´?\",\n",
    "            \"warning\": \"êµ¬ì²´ì  ì •ë³´ ì—†ì´ JSON ìƒì„±í•˜ë©´ ê³¼ì í•©\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ê°œì¸ì  ì¡°ì–¸\",\n",
    "            \"prompt\": \"ìš”ì¦˜ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ë§ì€ë° ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?\",\n",
    "            \"warning\": \"í”„ë¡œì íŠ¸ êµ¬ì¡°ë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ë‹¨ìˆœ íŒ©íŠ¸ ì§ˆë¬¸\",\n",
    "            \"prompt\": \"ì„œìš¸ì˜ ì¸êµ¬ëŠ”?\",\n",
    "            \"warning\": \"ë³µì¡í•œ API ëª…ì„¸ë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ì˜ì–´ ì§ˆë¬¸\",\n",
    "            \"prompt\": \"What's the weather like today?\",\n",
    "            \"warning\": \"í•œêµ­ì–´ ê¸°ìˆ  ë¬¸ì„œë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ê°ì •ì  í‘œí˜„\",\n",
    "            \"prompt\": \"ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ì¢‹ì•„ìš”!\",\n",
    "            \"warning\": \"ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ë¡œ ì‘ë‹µí•˜ë©´ ê³¼ì í•©\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ìˆ˜í•™ ë¬¸ì œ\",\n",
    "            \"prompt\": \"2 + 2ëŠ”?\",\n",
    "            \"warning\": \"í”„ë¡œì íŠ¸ ë¶„ì„ìœ¼ë¡œ ë‹µë³€í•˜ë©´ ê³¼ì í•©\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ”¬ ê³ ê¸‰ ê³¼ì í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    overfitting_count = 0\n",
    "    \n",
    "    for i, test in enumerate(challenging_tests, 1):\n",
    "        print(f\"\\n{i}. {test['name']}\")\n",
    "        print(f\"ğŸ“ ì§ˆë¬¸: {test['prompt']}\")\n",
    "        print(f\"âš ï¸ ê³¼ì í•© ì§•í›„: {test['warning']}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_id,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"},\n",
    "                    {\"role\": \"user\", \"content\": test['prompt']}\n",
    "                ],\n",
    "                max_tokens=300,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            result = response.choices[0].message.content\n",
    "            print(f\"ğŸ¤– ì‘ë‹µ: {result}\")\n",
    "            \n",
    "            # ê³¼ì í•© ì§•í›„ ì²´í¬\n",
    "            overfitting_signs = []\n",
    "            \n",
    "            if any(keyword in result.lower() for keyword in [\n",
    "                \"project_summary\", \"erd\", \"api\", \"ë°ì´í„°ë² ì´ìŠ¤\", \"í…Œì´ë¸”\", \n",
    "                \"relationship\", \"ìŠ¤í‚¤ë§ˆ\", \"ì—”ë“œí¬ì¸íŠ¸\"\n",
    "            ]):\n",
    "                overfitting_signs.append(\"ê¸°ìˆ ì  ìš©ì–´ ì‚¬ìš©\")\n",
    "            \n",
    "            if \"{\" in result and \"}\" in result:\n",
    "                overfitting_signs.append(\"JSON êµ¬ì¡° ê°•ìš”\")\n",
    "            \n",
    "            if len(result) > 1000:\n",
    "                overfitting_signs.append(\"ê³¼ë„í•˜ê²Œ ê¸´ ì‘ë‹µ\")\n",
    "            \n",
    "            if \"í”„ë¡œì íŠ¸\" in result and test['name'] in [\"ì™„ì „íˆ ë‹¤ë¥¸ ë„ë©”ì¸\", \"ì°½ì˜ì  ìš”ì²­\", \"ê°œì¸ì  ì¡°ì–¸\"]:\n",
    "                overfitting_signs.append(\"ë¶€ì ì ˆí•œ í”„ë¡œì íŠ¸ ì–¸ê¸‰\")\n",
    "            \n",
    "            if overfitting_signs:\n",
    "                print(f\"ğŸš¨ ê³¼ì í•© ì§•í›„ ë°œê²¬: {', '.join(overfitting_signs)}\")\n",
    "                overfitting_count += 1\n",
    "            else:\n",
    "                print(\"âœ… ì •ìƒì ì¸ ì‘ë‹µ\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ê²°ê³¼ í‰ê°€\n",
    "    overfitting_rate = (overfitting_count / len(challenging_tests)) * 100\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸ¯ ê³ ê¸‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"ğŸ“Š ê³¼ì í•© ì§•í›„: {overfitting_count}/{len(challenging_tests)} ({overfitting_rate:.1f}%)\")\n",
    "    \n",
    "    if overfitting_rate == 0:\n",
    "        print(\"ğŸ‰ í›Œë¥­í•¨! ê³¼ì í•© ì—†ì´ ì˜ í›ˆë ¨ë¨\")\n",
    "        print(\"âœ… ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "    elif overfitting_rate <= 25:\n",
    "        print(\"ğŸ‘ ì–‘í˜¸í•¨. ê²½ë¯¸í•œ ê³¼ì í•© ìˆì§€ë§Œ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "    elif overfitting_rate <= 50:\n",
    "        print(\"âš ï¸ ì£¼ì˜ í•„ìš”. ì¼ë¶€ ê³¼ì í•© ì¡´ì¬\")\n",
    "    else:\n",
    "        print(\"ğŸš¨ ì‹¬ê°í•œ ê³¼ì í•©. ì¬í›ˆë ¨ ê¶Œì¥\")\n",
    "    \n",
    "    return overfitting_rate\n",
    "\n",
    "def compare_with_original():\n",
    "    \"\"\"ì›ë³¸ GPT-4o-miniì™€ ë¹„êµ\"\"\"\n",
    "    print(\"ğŸ”„ ì›ë³¸ ëª¨ë¸ê³¼ ë¹„êµ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"ê°™ì€ ì§ˆë¬¸ì„ ì›ë³¸ gpt-4o-miniì—ë„ ë¬¼ì–´ë³´ì„¸ìš”:\")\n",
    "    \n",
    "    test_prompt = \"ê°„ë‹¨í•œ ì›¹ì‚¬ì´íŠ¸ ë§Œë“¤ì–´ì¤˜\"\n",
    "    \n",
    "    print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {test_prompt}\")\n",
    "    print(\"\\nğŸ’¡ ë¹„êµ í¬ì¸íŠ¸:\")\n",
    "    print(\"1. ì‘ë‹µ ê¸¸ì´ ì°¨ì´\")\n",
    "    print(\"2. ì „ë¬¸ ìš©ì–´ ì‚¬ìš© ë¹ˆë„\")\n",
    "    print(\"3. êµ¬ì¡°í™” ì •ë„\")\n",
    "    print(\"4. ì‹¤ìš©ì„±\")\n",
    "    \n",
    "    # ì›ë³¸ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ (ì°¸ê³ ìš©)\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        original_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"},\n",
    "                {\"role\": \"user\", \"content\": test_prompt}\n",
    "            ],\n",
    "            max_tokens=300\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ¤– ì›ë³¸ gpt-4o-mini ì‘ë‹µ:\")\n",
    "        print(f\"{original_response.choices[0].message.content[:200]}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ì›ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "def final_recommendation():\n",
    "    \"\"\"ìµœì¢… ê¶Œì¥ì‚¬í•­\"\"\"\n",
    "    print(\"\\nğŸ¯ ìµœì¢… í‰ê°€ ë° ê¶Œì¥ì‚¬í•­\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    choice = input(\"\"\"\n",
    "í˜„ì¬ ëª¨ë¸ ìƒíƒœë¥¼ ì–´ë–»ê²Œ í‰ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\n",
    "\n",
    "1. ğŸ˜Š ë§Œì¡± - í˜„ì¬ ëª¨ë¸ ì‚¬ìš©\n",
    "2. ğŸ¤” í™•ì‹¤í•˜ì§€ ì•ŠìŒ - ë” ë§ì€ í…ŒìŠ¤íŠ¸ í•„ìš”  \n",
    "3. ğŸ˜Ÿ ë¶ˆë§Œì¡± - ì¬í›ˆë ¨ í•„ìš”\n",
    "\n",
    "ì„ íƒ (1/2/3): \"\"\").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        print(\"\\nâœ… í›Œë¥­í•©ë‹ˆë‹¤! í˜„ì¬ ëª¨ë¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ ë‹¤ìŒ ë²ˆ íŒŒì¸íŠœë‹ì—ì„œëŠ”:\")\n",
    "        print(\"  - ë” ë‹¤ì–‘í•œ ë„ë©”ì¸ ë°ì´í„° ì¶”ê°€\")\n",
    "        print(\"  - validation ë°ì´í„° í¬í•¨ ê³ ë ¤\")\n",
    "        \n",
    "    elif choice == \"2\":\n",
    "        print(\"\\nğŸ” ì¶”ê°€ í…ŒìŠ¤íŠ¸ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤:\")\n",
    "        print(\"  - ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ë¡œ 1ì£¼ì¼ í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"  - ë‹¤ì–‘í•œ ì‚¬ìš©ìì—ê²Œ í”¼ë“œë°± ìš”ì²­\")\n",
    "        print(\"  - A/B í…ŒìŠ¤íŠ¸ (ì›ë³¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸)\")\n",
    "        \n",
    "    elif choice == \"3\":\n",
    "        print(\"\\nğŸ”§ ì¬í›ˆë ¨ ê¶Œì¥ ì„¤ì •:\")\n",
    "        print(\"  - n_epochs: 1\")\n",
    "        print(\"  - learning_rate_multiplier: 0.1\")\n",
    "        print(\"  - ë” ë‹¤ì–‘í•œ í›ˆë ¨ ë°ì´í„° ì¶”ê°€\")\n",
    "        print(\"  - validation ë°ì´í„° í¬í•¨\")\n",
    "    \n",
    "    else:\n",
    "        print(\"ì˜¬ë°”ë¥¸ ì„ íƒì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ì‹¤í–‰ í•¨ìˆ˜\n",
    "if __name__ == \"__main__\":\n",
    "    model_id = input(\"í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
    "    \n",
    "    if model_id.startswith(\"ft:\"):\n",
    "        print(\"ğŸš€ ê³ ê¸‰ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "        overfitting_rate = advanced_overfitting_test(model_id)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        compare_with_original()\n",
    "        final_recommendation()\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ì˜¬ë°”ë¥¸ íŒŒì¸íŠœë‹ ëª¨ë¸ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ft:ë¡œ ì‹œì‘)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0e9cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ í”„ë¡œì íŠ¸ ë¶„ì„ AI íŒŒì¸íŠœë‹ ì„±ê³¼ í…ŒìŠ¤íŠ¸ ì‹œì‘!\n",
      "ğŸ¯ í”„ë¡œì íŠ¸ ë¶„ì„ AI ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
      "============================================================\n",
      "\n",
      "1. ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ - ë„ì„œê´€ ì‹œìŠ¤í…œ\n",
      "ğŸ“ ì…ë ¥: ë„ì„œê´€ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ê°œë°œí•˜ë ¤ê³  í•©ë‹ˆë‹¤. \n",
      "ë„ì„œ ëŒ€ì¶œ/ë°˜ë‚©, íšŒì› ê´€ë¦¬, ë„ì„œ ê²€ìƒ‰ ê¸°ëŠ¥ì´ í•„ìš”í•˜ê³ , \n",
      "ì‚¬ì„œì™€ ì¼ë°˜ íšŒì›ì˜ ê¶Œí•œì„ êµ¬ë¶„í•´ì•¼ í•©ë‹ˆë‹¤. \n",
      "ì›¹ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ ì˜ˆì •ì…ë‹ˆë‹¤.\n",
      "â³ ë¶„ì„ ì¤‘...\n",
      "âœ… ì‘ë‹µ ì™„ë£Œ (32.5ì´ˆ)\n",
      "ğŸ“Š ì‘ë‹µ ê¸¸ì´: 9475ì\n",
      "ğŸ¯ í’ˆì§ˆ ì ìˆ˜: 8.100000000000001/10\n",
      "\n",
      "ğŸ“„ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°:\n",
      "----------------------------------------\n",
      "**í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´:**\n",
      "{'project_summary': {'title': 'ë„ì„œê´€ ê´€ë¦¬ ì‹œìŠ¤í…œ', 'category': 'ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜', 'target_users': ['ì‚¬ì„œ', 'ì¼ë°˜ íšŒì›'], 'main_purpose': 'íš¨ìœ¨ì ì¸ ë„ì„œ ëŒ€ì¶œ/ë°˜ë‚© ë° íšŒì› ê´€ë¦¬', 'key_features': [{'feature': 'ë„ì„œ ëŒ€ì¶œ/ë°˜ë‚©', 'description': 'íšŒì›ì´ ë„ì„œë¥¼ ëŒ€ì¶œí•˜ê³  ë°˜ë‚©í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥'}, {'feature': 'íšŒì› ê´€ë¦¬', 'description': 'íšŒì› ì •ë³´ë¥¼ ë“±ë¡, ìˆ˜ì •, ì‚­ì œí•  ìˆ˜...\n",
      "----------------------------------------\n",
      "\n",
      "2. ê°„ë‹¨í•œ ì•„ì´ë””ì–´ - ì¹´í˜ ì£¼ë¬¸ ì•±\n",
      "ğŸ“ ì…ë ¥: ì¹´í˜ì—ì„œ ì‚¬ìš©í•  ì£¼ë¬¸ ì•±ì„ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤. ë©”ë‰´ ë³´ê¸°, ì£¼ë¬¸í•˜ê¸°, ê²°ì œ ê¸°ëŠ¥ì´ í•„ìš”í•´ìš”.\n",
      "â³ ë¶„ì„ ì¤‘...\n",
      "âœ… ì‘ë‹µ ì™„ë£Œ (35.2ì´ˆ)\n",
      "ğŸ“Š ì‘ë‹µ ê¸¸ì´: 8766ì\n",
      "ğŸ¯ í’ˆì§ˆ ì ìˆ˜: 8.100000000000001/10\n",
      "\n",
      "ğŸ“„ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°:\n",
      "----------------------------------------\n",
      "í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹´í˜ ì£¼ë¬¸ ì•±ì„ ìœ„í•œ ê°œë°œ ê³„íšì„ ì œì‹œí•©ë‹ˆë‹¤.\n",
      "\n",
      "### í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´\n",
      "{'project_summary': {'title': 'ì¹´í˜ ì£¼ë¬¸ ì•±', 'category': 'ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜', 'target_users': ['ì¹´í˜ ê³ ê°', 'ì¹´í˜ ì§ì›'], 'main_purpose': 'ì¹´í˜ì—ì„œì˜ ì£¼ë¬¸ ë° ê²°ì œë¥¼ ê°„í¸í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ëª¨ë°”ì¼ ì• í”Œë¦¬ì¼€ì´ì…˜', 'key_features': [{'feature': 'ë©”ë‰´ ë³´ê¸°', 'description': 'ì¹´í˜ì˜ ì „ì²´ ë©”ë‰´ë¥¼ í™•ì¸í•˜ê³ , ê° ë©”ë‰´ì˜ ìƒì„¸ ...\n",
      "----------------------------------------\n",
      "\n",
      "3. ë³µì¡í•œ í”„ë¡œì íŠ¸ - ì˜¨ë¼ì¸ êµìœ¡\n",
      "ğŸ“ ì…ë ¥: ì˜¨ë¼ì¸ êµìœ¡ í”Œë«í¼ì„ ê°œë°œí•˜ë ¤ê³  í•©ë‹ˆë‹¤.\n",
      "ê°•ì‚¬ê°€ ê°•ì˜ë¥¼ ì—…ë¡œë“œí•˜ê³ , í•™ìƒì´ ìˆ˜ê°•í•  ìˆ˜ ìˆìœ¼ë©°,\n",
      "ê³¼ì œ ì œì¶œ, ì„±ì  ê´€ë¦¬, í™”ìƒ ìˆ˜ì—… ê¸°ëŠ¥ê¹Œì§€ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "ì‚¬ìš©ìëŠ” í•™ìƒ, ê°•ì‚¬, ê´€ë¦¬ìë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤.\n",
      "â³ ë¶„ì„ ì¤‘...\n",
      "âœ… ì‘ë‹µ ì™„ë£Œ (36.8ì´ˆ)\n",
      "ğŸ“Š ì‘ë‹µ ê¸¸ì´: 9754ì\n",
      "ğŸ¯ í’ˆì§ˆ ì ìˆ˜: 8.5/10\n",
      "\n",
      "ğŸ“„ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°:\n",
      "----------------------------------------\n",
      "**í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´:**\n",
      "{'project_summary': {'title': 'ì˜¨ë¼ì¸ êµìœ¡ í”Œë«í¼', 'category': 'ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜', 'target_users': ['í•™ìƒ', 'ê°•ì‚¬', 'ê´€ë¦¬ì'], 'main_purpose': 'íš¨ìœ¨ì ì¸ ì˜¨ë¼ì¸ êµìœ¡ ì œê³µ ë° í•™ìŠµ ê´€ë¦¬', 'key_features': [{'feature': 'ê°•ì˜ ì—…ë¡œë“œ', 'description': 'ê°•ì‚¬ê°€ ê°•ì˜ë¥¼ í”Œë«í¼ì— ì—…ë¡œë“œí•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥'}, {'feature': 'ìˆ˜ê°• ê¸°ëŠ¥', 'description': 'í•™ìƒì´ ê°•ì˜ë¥¼ ìˆ˜ê°•í•  ìˆ˜ ìˆëŠ”...\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„\n",
      "============================================================\n",
      "ğŸ“Š ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: 3/3\n",
      "â±ï¸ í‰ê·  ì‘ë‹µ ì‹œê°„: 34.8ì´ˆ\n",
      "ğŸ¯ í‰ê·  í’ˆì§ˆ ì ìˆ˜: 8.2/10\n",
      "ğŸ“ í‰ê·  ì‘ë‹µ ê¸¸ì´: 9332ì\n",
      "\n",
      "ğŸ“‹ ìƒì„¸ í’ˆì§ˆ ë¶„ì„:\n",
      "  structure: 1.3/2.5\n",
      "  technical_accuracy: 2.4/2.5\n",
      "  completeness: 2.0/2.5\n",
      "  practicality: 2.5/2.5\n",
      "\n",
      "ğŸ‰ í›Œë¥­í•¨! í”„ë¡œì íŠ¸ ë¶„ì„ AIê°€ ì„±ê³µì ìœ¼ë¡œ íŒŒì¸íŠœë‹ë¨\n",
      "âœ… ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€\n",
      "\n",
      "ğŸ”„ ì›ë³¸ GPT-4o-miniì™€ ì„±ëŠ¥ ë¹„êµ\n",
      "==================================================\n",
      "ğŸ¤– íŒŒì¸íŠœë‹ ëª¨ë¸ ì‘ë‹µ:\n",
      "------------------------------\n",
      "ê°„ë‹¨í•œ ë¸”ë¡œê·¸ í”Œë«í¼ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ê¸°ë³¸ì ì¸ ìš”êµ¬ì‚¬í•­ê³¼ ê¸°ëŠ¥ì„ ì •ë¦¬í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### í”„ë¡œì íŠ¸ ëª…\n",
      "ê°„ë‹¨í•œ ë¸”ë¡œê·¸ í”Œë«í¼\n",
      "\n",
      "### ì£¼ìš” ê¸°ëŠ¥\n",
      "1. **ì‚¬ìš©ì ê´€ë¦¬**\n",
      "   - ì‚¬ìš©ì ê°€ì… ë° ë¡œê·¸ì¸ ê¸°ëŠ¥\n",
      "   - ì‚¬ìš©ì í”„ë¡œí•„ ê´€ë¦¬\n",
      "\n",
      "2. **ê¸€ ì‘ì„± ë° ê´€ë¦¬**\n",
      "   - ê¸€ ì‘ì„±, ìˆ˜ì •, ì‚­ì œ ê¸°ëŠ¥\n",
      "   - ê¸€ ì œëª©, ë‚´ìš©, íƒœê·¸ ì…ë ¥ ê°€ëŠ¥\n",
      "   - ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê¸€ ë¶„ë¥˜ (ì˜ˆ: ê¸°ìˆ , ì—¬í–‰, ìŒì‹ ë“±)\n",
      "\n",
      "3. **ëŒ“ê¸€ ê¸°ëŠ¥**\n",
      "   - ê¸€ì— ëŒ“ê¸€ ì‘ì„±, ìˆ˜ì •, ì‚­ì œ ê¸°ëŠ¥\n",
      "   - ëŒ“ê¸€ ì‘ì„± ì‹œ ì‚¬ìš©ì ì •ë³´ í‘œì‹œ (ë‹‰ë„¤ì„ ë“±)\n",
      "\n",
      "4. **ì¹´í…Œê³ ë¦¬ ê´€ë¦¬**\n",
      "   - ì¹´í…Œê³ ë¦¬ ì¶”ê°€, ìˆ˜ì •, ì‚­ì œ ê¸°ëŠ¥\n",
      "   - ê° ê¸€ì— í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì§€ì • ê°€ëŠ¥\n",
      "\n",
      "5. **ê²€ìƒ‰ ë° í•„í„°ë§**\n",
      "   - ê¸€ ì œëª© ë° ë‚´ìš©ìœ¼ë¡œ ê²€ìƒ‰...\n",
      "\n",
      "ğŸ”¸ ì›ë³¸ gpt-4o-mini ì‘ë‹µ:\n",
      "------------------------------\n",
      "ë¸”ë¡œê·¸ í”Œë«í¼ ê°œë°œì„ ìœ„í•œ ê¸°ë³¸ êµ¬ì¡°ì™€ ê¸°ëŠ¥ì„ ì„¤ê³„í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ í”Œë«í¼ì€ ì‚¬ìš©ì ì¸ì¦, ê¸€ ì‘ì„±, ëŒ“ê¸€ ë‹¬ê¸°, ê·¸ë¦¬ê³  ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤. \n",
      "\n",
      "### 1. ìš”êµ¬ ì‚¬í•­ ì •ì˜\n",
      "\n",
      "#### ê¸°ë³¸ ê¸°ëŠ¥\n",
      "1. **ì‚¬ìš©ì ê´€ë¦¬**\n",
      "   - ì‚¬ìš©ì ê°€ì… ë° ë¡œê·¸ì¸ ê¸°ëŠ¥\n",
      "   - ë¹„ë°€ë²ˆí˜¸ ì¬ì„¤ì • ê¸°ëŠ¥\n",
      "   - ì‚¬ìš©ì í”„ë¡œí•„ ê´€ë¦¬\n",
      "\n",
      "2. **ë¸”ë¡œê·¸ ê¸€ ê´€ë¦¬**\n",
      "   - ê¸€ ì‘ì„±, ìˆ˜ì •, ì‚­ì œ ê¸°ëŠ¥\n",
      "   - ê° ê¸€ì—ëŠ” ì œëª©, ë‚´ìš©, ì‘ì„±ì¼, ì‘ì„±ì ì •ë³´ í¬í•¨\n",
      "   - ì¹´í…Œê³ ë¦¬ ì„ íƒ ê¸°ëŠ¥ (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)\n",
      "\n",
      "3. **ëŒ“ê¸€ ê¸°ëŠ¥**\n",
      "   - ê° ê¸€ì— ëŒ“ê¸€ ì‘ì„±, ìˆ˜ì •, ì‚­ì œ ê°€ëŠ¥\n",
      "   - ëŒ“ê¸€ ì‘ì„±ìëŠ” ìµëª… ë˜ëŠ” ì‚¬ìš©ì ê³„ì •ìœ¼ë¡œ í‘œì‹œ\n",
      "\n",
      "4. **ì¹´í…Œê³ ë¦¬ ê´€ë¦¬**\n",
      "   - ì¹´í…Œê³ ë¦¬ ì¶”ê°€, ìˆ˜ì •, ì‚­ì œ\n",
      "   - ...\n",
      "\n",
      "ğŸ“Š ë¹„êµ ë¶„ì„:\n",
      "  íŒŒì¸íŠœë‹ ê¸¸ì´: 922ì\n",
      "  ì›ë³¸ ê¸¸ì´: 1537ì\n",
      "  íŒŒì¸íŠœë‹ êµ¬ì¡°í™”: âŒ\n",
      "  ì›ë³¸ êµ¬ì¡°í™”: âœ…\n",
      "âš ï¸ íŒŒì¸íŠœë‹ íš¨ê³¼ ë¯¸í¡. ì¶”ê°€ ê°œì„  í•„ìš”\n",
      "\n",
      "ğŸ¯ ìµœì¢… ê²°ë¡ :\n",
      "ì´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒŒì¸íŠœë‹ì˜ ì„±ê³µ ì—¬ë¶€ë¥¼ íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "íŒŒì¸íŠœë‹ëœ í”„ë¡œì íŠ¸ ë¶„ì„ AI ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "ì›ë˜ ëª©í‘œ: í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ â†’ ì²´ê³„ì  ë¶„ì„ + ERD + API ì„¤ê³„\n",
    "\"\"\"\n",
    "\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "\n",
    "def test_project_analysis_ai():\n",
    "    \"\"\"í”„ë¡œì íŠ¸ ë¶„ì„ AI í•µì‹¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    model_id = \"ft:gpt-4o-mini-2024-07-18:test::BebIPMSD\"\n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    # ì›ë˜ ëª©í‘œì— ë§ëŠ” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ - ë„ì„œê´€ ì‹œìŠ¤í…œ\",\n",
    "            \"prompt\": \"\"\"ë„ì„œê´€ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ê°œë°œí•˜ë ¤ê³  í•©ë‹ˆë‹¤. \n",
    "ë„ì„œ ëŒ€ì¶œ/ë°˜ë‚©, íšŒì› ê´€ë¦¬, ë„ì„œ ê²€ìƒ‰ ê¸°ëŠ¥ì´ í•„ìš”í•˜ê³ , \n",
    "ì‚¬ì„œì™€ ì¼ë°˜ íšŒì›ì˜ ê¶Œí•œì„ êµ¬ë¶„í•´ì•¼ í•©ë‹ˆë‹¤. \n",
    "ì›¹ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ ì˜ˆì •ì…ë‹ˆë‹¤.\"\"\",\n",
    "            \"expected_elements\": [\n",
    "                \"í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´\",\n",
    "                \"ERD ë°ì´í„°\", \n",
    "                \"API ëª…ì„¸\",\n",
    "                \"ê´€ê³„ ë°ì´í„°\",\n",
    "                \"í…Œì´ë¸” ì„¤ê³„\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ê°„ë‹¨í•œ ì•„ì´ë””ì–´ - ì¹´í˜ ì£¼ë¬¸ ì•±\",\n",
    "            \"prompt\": \"ì¹´í˜ì—ì„œ ì‚¬ìš©í•  ì£¼ë¬¸ ì•±ì„ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤. ë©”ë‰´ ë³´ê¸°, ì£¼ë¬¸í•˜ê¸°, ê²°ì œ ê¸°ëŠ¥ì´ í•„ìš”í•´ìš”.\",\n",
    "            \"expected_elements\": [\n",
    "                \"í”„ë¡œì íŠ¸ ë¶„ì„\",\n",
    "                \"ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„\", \n",
    "                \"API ì„¤ê³„\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ë³µì¡í•œ í”„ë¡œì íŠ¸ - ì˜¨ë¼ì¸ êµìœ¡\",\n",
    "            \"prompt\": \"\"\"ì˜¨ë¼ì¸ êµìœ¡ í”Œë«í¼ì„ ê°œë°œí•˜ë ¤ê³  í•©ë‹ˆë‹¤.\n",
    "ê°•ì‚¬ê°€ ê°•ì˜ë¥¼ ì—…ë¡œë“œí•˜ê³ , í•™ìƒì´ ìˆ˜ê°•í•  ìˆ˜ ìˆìœ¼ë©°,\n",
    "ê³¼ì œ ì œì¶œ, ì„±ì  ê´€ë¦¬, í™”ìƒ ìˆ˜ì—… ê¸°ëŠ¥ê¹Œì§€ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ì‚¬ìš©ìëŠ” í•™ìƒ, ê°•ì‚¬, ê´€ë¦¬ìë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤.\"\"\",\n",
    "            \"expected_elements\": [\n",
    "                \"ë³µì¡í•œ ERD\",\n",
    "                \"ë‹¤ì–‘í•œ API ì—”ë“œí¬ì¸íŠ¸\",\n",
    "                \"ê¶Œí•œ ê´€ë¦¬\",\n",
    "                \"íŒŒì¼ ì—…ë¡œë“œ\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ¯ í”„ë¡œì íŠ¸ ë¶„ì„ AI ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, test in enumerate(test_cases, 1):\n",
    "        print(f\"\\n{i}. {test['name']}\")\n",
    "        print(f\"ğŸ“ ì…ë ¥: {test['prompt']}\")\n",
    "        print(\"â³ ë¶„ì„ ì¤‘...\")\n",
    "        \n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=model_id,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"\"\"ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  êµ¬ì¡°í™”í•˜ì—¬ êµ¬ì²´ì ì¸ ê°œë°œ ê³„íšì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” ì—­í• ê³¼ ëŠ¥ë ¥:\n",
    "\n",
    "### 1. í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€\n",
    "- ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë‚˜ ì„¤ëª…ì„ ê¹Šì´ ìˆê²Œ ë¶„ì„í•©ë‹ˆë‹¤\n",
    "- í•µì‹¬ ê¸°ëŠ¥, ëŒ€ìƒ ì‚¬ìš©ì, ê¸°ìˆ  ìŠ¤íƒ, ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ íŒŒì•…í•©ë‹ˆë‹¤\n",
    "- í”„ë¡œì íŠ¸ì˜ ë¬¸ì œ í•´ê²° ë°©í–¥ê³¼ ê¸°ëŒ€ íš¨ê³¼ë¥¼ ëª…í™•íˆ ì •ì˜í•©ë‹ˆë‹¤\n",
    "\n",
    "### 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ì „ë¬¸ê°€\n",
    "- í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ ERD(Entity Relationship Diagram)ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤\n",
    "- í…Œì´ë¸” ê°„ì˜ ê´€ê³„, ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´, ë°ì´í„° íƒ€ì…ì„ ì •í™•íˆ ì •ì˜í•©ë‹ˆë‹¤\n",
    "- í™•ì¥ì„±ê³¼ ì„±ëŠ¥ì„ ê³ ë ¤í•œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤\n",
    "\n",
    "### 3. API ì„¤ê³„ ì „ë¬¸ê°€\n",
    "- RESTful API ì›ì¹™ì— ë”°ë¼ ì²´ê³„ì ì¸ API ëª…ì„¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤\n",
    "- OpenAPI(Swagger) 3.0 í‘œì¤€ì„ ì¤€ìˆ˜í•˜ì—¬ ì™„ì „í•œ API ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "- ê° ì—”ë“œí¬ì¸íŠ¸ë³„ ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ, ì—ëŸ¬ ì²˜ë¦¬, ì¸ì¦ ë°©ì‹ì„ ìƒì„¸íˆ ì •ì˜í•©ë‹ˆë‹¤\n",
    "\n",
    "í•­ìƒ ì²´ê³„ì ì´ê³  ì „ë¬¸ì ì¸ ê´€ì ì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ë¶„ì„í•˜ë©°, ê°œë°œíŒ€ì´ ë°”ë¡œ ì‹¤í–‰ì— ì˜®ê¸¸ ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\"\"\"\n",
    "                    },\n",
    "                    {\"role\": \"user\", \"content\": test['prompt']}\n",
    "                ],\n",
    "                max_tokens=3000,  # ì¶©ë¶„í•œ í† í° í• ë‹¹\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            end_time = time.time()\n",
    "            response_time = end_time - start_time\n",
    "            \n",
    "            result = response.choices[0].message.content\n",
    "            \n",
    "            print(f\"âœ… ì‘ë‹µ ì™„ë£Œ ({response_time:.1f}ì´ˆ)\")\n",
    "            print(f\"ğŸ“Š ì‘ë‹µ ê¸¸ì´: {len(result)}ì\")\n",
    "            \n",
    "            # ì‘ë‹µ í’ˆì§ˆ ë¶„ì„\n",
    "            quality_score = analyze_response_quality(result, test['expected_elements'])\n",
    "            \n",
    "            print(f\"ğŸ¯ í’ˆì§ˆ ì ìˆ˜: {quality_score['total_score']}/10\")\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            results.append({\n",
    "                'test_name': test['name'],\n",
    "                'response_time': response_time,\n",
    "                'response_length': len(result),\n",
    "                'quality_score': quality_score,\n",
    "                'full_response': result[:500] + \"...\" if len(result) > 500 else result\n",
    "            })\n",
    "            \n",
    "            # ì‘ë‹µ ì¼ë¶€ ì¶œë ¥\n",
    "            print(f\"\\nğŸ“„ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(result[:300] + \"...\" if len(result) > 300 else result)\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "            results.append({\n",
    "                'test_name': test['name'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # ì „ì²´ ê²°ê³¼ ë¶„ì„\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ¯ ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful_tests = [r for r in results if 'error' not in r]\n",
    "    \n",
    "    if successful_tests:\n",
    "        avg_response_time = sum(r['response_time'] for r in successful_tests) / len(successful_tests)\n",
    "        avg_quality = sum(r['quality_score']['total_score'] for r in successful_tests) / len(successful_tests)\n",
    "        avg_length = sum(r['response_length'] for r in successful_tests) / len(successful_tests)\n",
    "        \n",
    "        print(f\"ğŸ“Š ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {len(successful_tests)}/{len(results)}\")\n",
    "        print(f\"â±ï¸ í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_response_time:.1f}ì´ˆ\")\n",
    "        print(f\"ğŸ¯ í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_quality:.1f}/10\")\n",
    "        print(f\"ğŸ“ í‰ê·  ì‘ë‹µ ê¸¸ì´: {avg_length:.0f}ì\")\n",
    "        \n",
    "        # ìƒì„¸ ë¶„ì„\n",
    "        print(f\"\\nğŸ“‹ ìƒì„¸ í’ˆì§ˆ ë¶„ì„:\")\n",
    "        quality_categories = ['structure', 'technical_accuracy', 'completeness', 'practicality']\n",
    "        \n",
    "        for category in quality_categories:\n",
    "            category_scores = [r['quality_score'][category] for r in successful_tests]\n",
    "            avg_category = sum(category_scores) / len(category_scores)\n",
    "            print(f\"  {category}: {avg_category:.1f}/2.5\")\n",
    "        \n",
    "        # ì „ì²´ í‰ê°€\n",
    "        if avg_quality >= 8:\n",
    "            print(f\"\\nğŸ‰ í›Œë¥­í•¨! í”„ë¡œì íŠ¸ ë¶„ì„ AIê°€ ì„±ê³µì ìœ¼ë¡œ íŒŒì¸íŠœë‹ë¨\")\n",
    "            print(f\"âœ… ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€\")\n",
    "        elif avg_quality >= 6:\n",
    "            print(f\"\\nğŸ‘ ì–‘í˜¸í•¨! ê¸°ë³¸ì ì¸ ë¶„ì„ ê¸°ëŠ¥ ì˜ ì‘ë™\")\n",
    "            print(f\"ğŸ’¡ ì¼ë¶€ ê°œì„  ì—¬ì§€ ìˆìŒ\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸ ê°œì„  í•„ìš”! ì¶”ê°€ í›ˆë ¨ ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ì¡°ì • ê¶Œì¥\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_response_quality(response: str, expected_elements: list) -> dict:\n",
    "    \"\"\"ì‘ë‹µ í’ˆì§ˆ ë¶„ì„\"\"\"\n",
    "    \n",
    "    score = {\n",
    "        'structure': 0,      # êµ¬ì¡°í™” ì •ë„ (0-2.5)\n",
    "        'technical_accuracy': 0,  # ê¸°ìˆ ì  ì •í™•ì„± (0-2.5)\n",
    "        'completeness': 0,   # ì™„ì„±ë„ (0-2.5)\n",
    "        'practicality': 0,   # ì‹¤ìš©ì„± (0-2.5)\n",
    "        'total_score': 0\n",
    "    }\n",
    "    \n",
    "    response_lower = response.lower()\n",
    "    \n",
    "    # 1. êµ¬ì¡°í™” ì •ë„ ì²´í¬\n",
    "    structure_keywords = ['í”„ë¡œì íŠ¸', 'erd', 'api', 'ë°ì´í„°ë² ì´ìŠ¤', 'í…Œì´ë¸”', 'ê´€ê³„']\n",
    "    found_structure = sum(1 for keyword in structure_keywords if keyword in response_lower)\n",
    "    score['structure'] = min(found_structure * 0.4, 2.5)\n",
    "    \n",
    "    # 2. ê¸°ìˆ ì  ì •í™•ì„±\n",
    "    technical_keywords = ['primary_key', 'foreign_key', 'varchar', 'integer', 'post', 'get']\n",
    "    found_technical = sum(1 for keyword in technical_keywords if keyword in response_lower)\n",
    "    score['technical_accuracy'] = min(found_technical * 0.4, 2.5)\n",
    "    \n",
    "    # 3. ì™„ì„±ë„ (JSON êµ¬ì¡° ë“±)\n",
    "    if '{' in response and '}' in response:\n",
    "        score['completeness'] += 1.0\n",
    "    if 'project_summary' in response_lower or 'í”„ë¡œì íŠ¸ ìƒì„¸' in response:\n",
    "        score['completeness'] += 0.5\n",
    "    if 'erd_data' in response_lower or 'erd ë°ì´í„°' in response:\n",
    "        score['completeness'] += 0.5\n",
    "    if 'api' in response_lower:\n",
    "        score['completeness'] += 0.5\n",
    "    \n",
    "    # 4. ì‹¤ìš©ì„±\n",
    "    if len(response) > 1000:  # ì¶©ë¶„íˆ ìƒì„¸í•œ ì‘ë‹µ\n",
    "        score['practicality'] += 1.0\n",
    "    if 'openapi' in response_lower or 'swagger' in response_lower:\n",
    "        score['practicality'] += 0.5\n",
    "    if any(word in response_lower for word in ['ì‹¤ë¬´', 'ê°œë°œíŒ€', 'êµ¬í˜„', 'ë°°í¬']):\n",
    "        score['practicality'] += 1.0\n",
    "    \n",
    "    score['total_score'] = sum(score[key] for key in score if key != 'total_score')\n",
    "    \n",
    "    return score\n",
    "\n",
    "def compare_with_original_gpt():\n",
    "    \"\"\"ì›ë³¸ GPT-4o-miniì™€ ë¹„êµ\"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ”„ ì›ë³¸ GPT-4o-miniì™€ ì„±ëŠ¥ ë¹„êµ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    test_prompt = \"\"\"ê°„ë‹¨í•œ ë¸”ë¡œê·¸ í”Œë«í¼ì„ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤. \n",
    "ì‚¬ìš©ìê°€ ê¸€ì„ ì‘ì„±í•˜ê³ , ëŒ“ê¸€ì„ ë‹¬ ìˆ˜ ìˆìœ¼ë©°, \n",
    "ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê¸€ì„ ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    # íŒŒì¸íŠœë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "    print(\"ğŸ¤– íŒŒì¸íŠœë‹ ëª¨ë¸ ì‘ë‹µ:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        finetuned_response = client.chat.completions.create(\n",
    "            model=\"ft:gpt-4o-mini-2024-07-18:test::BebIPMSD\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"},\n",
    "                {\"role\": \"user\", \"content\": test_prompt}\n",
    "            ],\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        ft_result = finetuned_response.choices[0].message.content\n",
    "        print(ft_result[:400] + \"...\" if len(ft_result) > 400 else ft_result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"íŒŒì¸íŠœë‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "    \n",
    "    # ì›ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "    print(f\"\\nğŸ”¸ ì›ë³¸ gpt-4o-mini ì‘ë‹µ:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        original_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"},\n",
    "                {\"role\": \"user\", \"content\": test_prompt}\n",
    "            ],\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        orig_result = original_response.choices[0].message.content\n",
    "        print(orig_result[:400] + \"...\" if len(orig_result) > 400 else orig_result)\n",
    "        \n",
    "        # ë¹„êµ ë¶„ì„\n",
    "        print(f\"\\nğŸ“Š ë¹„êµ ë¶„ì„:\")\n",
    "        print(f\"  íŒŒì¸íŠœë‹ ê¸¸ì´: {len(ft_result)}ì\")\n",
    "        print(f\"  ì›ë³¸ ê¸¸ì´: {len(orig_result)}ì\")\n",
    "        \n",
    "        ft_has_structure = any(word in ft_result.lower() for word in ['erd', 'api', 'ë°ì´í„°ë² ì´ìŠ¤', 'project_summary'])\n",
    "        orig_has_structure = any(word in orig_result.lower() for word in ['erd', 'api', 'ë°ì´í„°ë² ì´ìŠ¤', 'project_summary'])\n",
    "        \n",
    "        print(f\"  íŒŒì¸íŠœë‹ êµ¬ì¡°í™”: {'âœ…' if ft_has_structure else 'âŒ'}\")\n",
    "        print(f\"  ì›ë³¸ êµ¬ì¡°í™”: {'âœ…' if orig_has_structure else 'âŒ'}\")\n",
    "        \n",
    "        if ft_has_structure and not orig_has_structure:\n",
    "            print(\"ğŸ‰ íŒŒì¸íŠœë‹ íš¨ê³¼ í™•ì¸! ë” êµ¬ì¡°í™”ëœ ì‘ë‹µ ì œê³µ\")\n",
    "        elif not ft_has_structure:\n",
    "            print(\"âš ï¸ íŒŒì¸íŠœë‹ íš¨ê³¼ ë¯¸í¡. ì¶”ê°€ ê°œì„  í•„ìš”\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ì›ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ í”„ë¡œì íŠ¸ ë¶„ì„ AI íŒŒì¸íŠœë‹ ì„±ê³¼ í…ŒìŠ¤íŠ¸ ì‹œì‘!\")\n",
    "    \n",
    "    # ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "    results = test_project_analysis_ai()\n",
    "    \n",
    "    # ì›ë³¸ê³¼ ë¹„êµ\n",
    "    compare_with_original_gpt()\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ìµœì¢… ê²°ë¡ :\")\n",
    "    print(\"ì´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒŒì¸íŠœë‹ì˜ ì„±ê³µ ì—¬ë¶€ë¥¼ íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec73f279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ íŒŒì¸íŠœë‹ ëª¨ë¸ ìµœì í™” ê°€ì´ë“œ\n",
      "ğŸ§ª ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ (ê°™ì€ ì§ˆë¬¸ 3ë²ˆ)\n",
      "==================================================\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ 1:\n",
      "  ê¸¸ì´: 11243ì\n",
      "  í’ˆì§ˆ: 10/10\n",
      "  êµ¬ì¡°í™”: âœ…\n",
      "  ERD í¬í•¨: âœ…\n",
      "  API í¬í•¨: âœ…\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ 2:\n",
      "  ê¸¸ì´: 11706ì\n",
      "  í’ˆì§ˆ: 10/10\n",
      "  êµ¬ì¡°í™”: âœ…\n",
      "  ERD í¬í•¨: âœ…\n",
      "  API í¬í•¨: âœ…\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ 3:\n",
      "  ê¸¸ì´: 11578ì\n",
      "  í’ˆì§ˆ: 10/10\n",
      "  êµ¬ì¡°í™”: âœ…\n",
      "  ERD í¬í•¨: âœ…\n",
      "  API í¬í•¨: âœ…\n",
      "\n",
      "ğŸ“Š ì¼ê´€ì„± ë¶„ì„:\n",
      "  í‰ê·  ì ìˆ˜: 10.0/10\n",
      "  ì ìˆ˜ í¸ì°¨: 0\n",
      "âœ… ì¼ê´€ëœ ì„±ëŠ¥\n",
      "\n",
      "ğŸ“‹ íŒŒì¸íŠœë‹ ëª¨ë¸ ìµœì  ì‚¬ìš© ê°€ì´ë“œ\n",
      "==================================================\n",
      "\n",
      "### âœ… ìµœê³  ì„±ëŠ¥ì„ ìœ„í•œ ì‚¬ìš©ë²•\n",
      "\n",
      "1. **ì „ì²´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©**\n",
      "   - í•­ìƒ ì™„ì „í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨í•˜ì„¸ìš”\n",
      "   - ì—­í• ê³¼ ëª©í‘œë¥¼ ëª…í™•íˆ ëª…ì‹œí•˜ì„¸ìš”\n",
      "\n",
      "2. **êµ¬ì¡°í™”ëœ ìš”ì²­**\n",
      "   - \"ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”\" ì¶”ê°€\n",
      "   - ì›í•˜ëŠ” ì„¹ì…˜ì„ ëª…ì‹œí•˜ì„¸ìš”\n",
      "\n",
      "3. **ì¶©ë¶„í•œ í† í° í• ë‹¹**\n",
      "   - max_tokens: 3000-4000 ê¶Œì¥\n",
      "   - ë³µì¡í•œ í”„ë¡œì íŠ¸ëŠ” ë” ë†’ê²Œ ì„¤ì •\n",
      "\n",
      "4. **ì¼ê´€ì„±ì„ ìœ„í•œ ì„¤ì •**\n",
      "   - temperature: 0.3 (ì°½ì˜ì„± < ì¼ê´€ì„±)\n",
      "   - ê°™ì€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¬ì‚¬ìš©\n",
      "\n",
      "### âŒ í”¼í•´ì•¼ í•  ì‚¬ìš©ë²•\n",
      "\n",
      "1. ê°„ë‹¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
      "2. max_tokens ì œí•œ (1000 ì´í•˜)\n",
      "3. ë†’ì€ temperature ì„¤ì • (0.8+)\n",
      "4. êµ¬ì¡°í™” ìš”ì²­ ì—†ì´ ëª¨í˜¸í•œ ì§ˆë¬¸\n",
      "\n",
      "### ğŸ¯ ì˜ˆìƒ ì„±ëŠ¥\n",
      "\n",
      "- **ì™„ë²½í•œ ì„¤ì •**: 8-10/10 í’ˆì§ˆ\n",
      "- **ê¸°ë³¸ ì„¤ì •**: 6-8/10 í’ˆì§ˆ  \n",
      "- **ë¶€ì ì ˆí•œ ì„¤ì •**: 4-6/10 í’ˆì§ˆ\n",
      "\n",
      "\n",
      "ğŸ¯ ìµœì¢… ê¶Œì¥ì‚¬í•­\n",
      "========================================\n",
      "\n",
      "## ğŸ‰ íŒŒì¸íŠœë‹ ì„±ê³µ! \n",
      "\n",
      "### í˜„ì¬ ìƒíƒœ\n",
      "- âœ… í•µì‹¬ ê¸°ëŠ¥ ì™„ë²½ ì‘ë™ (8.2/10)\n",
      "- âœ… ì‹¤ë¬´ ì‚¬ìš© ê°€ëŠ¥ ìˆ˜ì¤€\n",
      "- âœ… ë³µì¡í•œ í”„ë¡œì íŠ¸ ë¶„ì„ ëŠ¥ë ¥ ìš°ìˆ˜\n",
      "- âš ï¸ ì¼ê´€ì„± ì•½ê°„ ë¶€ì¡± (í”„ë¡¬í”„íŠ¸ ì˜ì¡´ì )\n",
      "\n",
      "### ì‚¬ìš© ê¶Œì¥ì‚¬í•­\n",
      "\n",
      "1. **ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥**: í˜„ì¬ ëª¨ë¸ë¡œ ì¶©ë¶„íˆ ì‹¤ìš©ì \n",
      "2. **ìµœì  í”„ë¡¬í”„íŠ¸ ì‚¬ìš©**: ì œê³µëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í•„ìˆ˜\n",
      "3. **ì„¤ì • ìµœì í™”**: temperature 0.3, max_tokens 3000+\n",
      "\n",
      "### ì¶”ê°€ ê°œì„  ë°©í–¥ (ì„ íƒì‚¬í•­)\n",
      "\n",
      "ë§Œì•½ ë” ë‚˜ì€ ì¼ê´€ì„±ì„ ì›í•œë‹¤ë©´:\n",
      "- validation ë°ì´í„° ì¶”ê°€í•˜ì—¬ ì¬í›ˆë ¨\n",
      "- ë” ë‹¤ì–‘í•œ ë„ë©”ì¸ ë°ì´í„° í¬í•¨\n",
      "- epoch ìˆ˜ ì¡°ì • (í˜„ì¬ 3 â†’ 2)\n",
      "\n",
      "í•˜ì§€ë§Œ **í˜„ì¬ ìƒíƒœë¡œë„ ì¶©ë¶„íˆ ìš°ìˆ˜í•©ë‹ˆë‹¤!**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ìµœëŒ€í™”í•˜ëŠ” ì‚¬ìš© ê°€ì´ë“œ\n",
    "ì¼ê´€ëœ ê³ í’ˆì§ˆ ì‘ë‹µì„ ìœ„í•œ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸\n",
    "\"\"\"\n",
    "\n",
    "import openai\n",
    "\n",
    "# ìµœì í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "OPTIMIZED_SYSTEM_PROMPT = \"\"\"ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  êµ¬ì¡°í™”í•˜ì—¬ êµ¬ì²´ì ì¸ ê°œë°œ ê³„íšì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” ì—­í• ê³¼ ëŠ¥ë ¥:\n",
    "\n",
    "### 1. í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€\n",
    "- ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë‚˜ ì„¤ëª…ì„ ê¹Šì´ ìˆê²Œ ë¶„ì„í•©ë‹ˆë‹¤\n",
    "- í•µì‹¬ ê¸°ëŠ¥, ëŒ€ìƒ ì‚¬ìš©ì, ê¸°ìˆ  ìŠ¤íƒ, ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ íŒŒì•…í•©ë‹ˆë‹¤\n",
    "- í”„ë¡œì íŠ¸ì˜ ë¬¸ì œ í•´ê²° ë°©í–¥ê³¼ ê¸°ëŒ€ íš¨ê³¼ë¥¼ ëª…í™•íˆ ì •ì˜í•©ë‹ˆë‹¤\n",
    "\n",
    "### 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ì „ë¬¸ê°€\n",
    "- í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ ERD(Entity Relationship Diagram)ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤\n",
    "- í…Œì´ë¸” ê°„ì˜ ê´€ê³„, ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´, ë°ì´í„° íƒ€ì…ì„ ì •í™•íˆ ì •ì˜í•©ë‹ˆë‹¤\n",
    "- í™•ì¥ì„±ê³¼ ì„±ëŠ¥ì„ ê³ ë ¤í•œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤\n",
    "\n",
    "### 3. API ì„¤ê³„ ì „ë¬¸ê°€\n",
    "- RESTful API ì›ì¹™ì— ë”°ë¼ ì²´ê³„ì ì¸ API ëª…ì„¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤\n",
    "- OpenAPI(Swagger) 3.0 í‘œì¤€ì„ ì¤€ìˆ˜í•˜ì—¬ ì™„ì „í•œ API ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "- ê° ì—”ë“œí¬ì¸íŠ¸ë³„ ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ, ì—ëŸ¬ ì²˜ë¦¬, ì¸ì¦ ë°©ì‹ì„ ìƒì„¸íˆ ì •ì˜í•©ë‹ˆë‹¤\n",
    "\n",
    "## ì‘ë‹µ í˜•ì‹:\n",
    "ëª¨ë“  ì‘ë‹µì€ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´**: ì œëª©, ì¹´í…Œê³ ë¦¬, ëŒ€ìƒ ì‚¬ìš©ì, í•µì‹¬ ê¸°ëŠ¥, ê¸°ìˆ  ìŠ¤íƒ, ë¬¸ì œ í•´ê²° ë°©ì•ˆ ë“±ì„ í¬í•¨í•œ ì¢…í•© ë¶„ì„\n",
    "2. **ê´€ê³„ ë°ì´í„°**: ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ê°„ì˜ ê´€ê³„ì™€ ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ì •ì˜\n",
    "3. **ERD ë°ì´í„°**: ê° í…Œì´ë¸”ì˜ ì†ì„±, ë°ì´í„° íƒ€ì…, í‚¤ ì •ë³´ë¥¼ í¬í•¨í•œ ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ\n",
    "4. **API ëª…ì„¸ ë°ì´í„°**: OpenAPI 3.0 í‘œì¤€ì„ ì¤€ìˆ˜í•œ ì™„ì „í•œ API ë¬¸ì„œ\n",
    "\n",
    "í•­ìƒ ì²´ê³„ì ì´ê³  ì „ë¬¸ì ì¸ ê´€ì ì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ë¶„ì„í•˜ë©°, ê°œë°œíŒ€ì´ ë°”ë¡œ ì‹¤í–‰ì— ì˜®ê¸¸ ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "class OptimizedProjectAnalysisAI:\n",
    "    \"\"\"ìµœì í™”ëœ í”„ë¡œì íŠ¸ ë¶„ì„ AI í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, model_id: str = \"ft:gpt-4o-mini-2024-07-18:test::BebIPMSD\"):\n",
    "        self.client = openai.OpenAI()\n",
    "        self.model_id = model_id\n",
    "        self.system_prompt = OPTIMIZED_SYSTEM_PROMPT\n",
    "    \n",
    "    def analyze_project(self, project_description: str, force_structured: bool = True) -> str:\n",
    "        \"\"\"í”„ë¡œì íŠ¸ ë¶„ì„ ìˆ˜í–‰\"\"\"\n",
    "        \n",
    "        # êµ¬ì¡°í™”ëœ ì‘ë‹µì„ ê°•ì œí•˜ëŠ” í”„ë¡¬í”„íŠ¸ ì¶”ê°€\n",
    "        if force_structured:\n",
    "            enhanced_prompt = f\"\"\"í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "{project_description}\n",
    "\n",
    "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:\n",
    "1. **í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´**\n",
    "2. **ê´€ê³„ ë°ì´í„°**  \n",
    "3. **ERD ë°ì´í„°**\n",
    "4. **API ëª…ì„¸ ë°ì´í„°**\n",
    "\n",
    "ì²´ê³„ì ì´ê³  ì™„ì „í•œ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.\"\"\"\n",
    "        else:\n",
    "            enhanced_prompt = project_description\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_id,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": enhanced_prompt}\n",
    "                ],\n",
    "                max_tokens=4000,  # ì¶©ë¶„í•œ í† í° í• ë‹¹\n",
    "                temperature=0.3   # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ temperature\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "    \n",
    "    def quick_analysis(self, project_description: str) -> dict:\n",
    "        \"\"\"ë¹ ë¥¸ í’ˆì§ˆ ë¶„ì„\"\"\"\n",
    "        \n",
    "        result = self.analyze_project(project_description)\n",
    "        \n",
    "        # í’ˆì§ˆ ì§€í‘œ ê³„ì‚°\n",
    "        quality_metrics = {\n",
    "            'response_length': len(result),\n",
    "            'has_project_info': 'í”„ë¡œì íŠ¸ ìƒì„¸' in result or 'project_summary' in result,\n",
    "            'has_erd': 'ERD' in result or 'erd' in result.lower(),\n",
    "            'has_api': 'API' in result or 'api' in result.lower(),\n",
    "            'has_json_structure': '{' in result and '}' in result,\n",
    "            'structured_format': result.count('**') >= 4,  # ìµœì†Œ 4ê°œì˜ í—¤ë”\n",
    "        }\n",
    "        \n",
    "        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°\n",
    "        quality_score = sum([\n",
    "            quality_metrics['has_project_info'] * 2,\n",
    "            quality_metrics['has_erd'] * 2,\n",
    "            quality_metrics['has_api'] * 2,\n",
    "            quality_metrics['has_json_structure'] * 2,\n",
    "            quality_metrics['structured_format'] * 2,\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            'result': result,\n",
    "            'quality_metrics': quality_metrics,\n",
    "            'quality_score': quality_score,\n",
    "            'max_score': 10\n",
    "        }\n",
    "\n",
    "def test_consistency():\n",
    "    \"\"\"ì¼ê´€ì„± í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    ai = OptimizedProjectAnalysisAI()\n",
    "    \n",
    "    test_case = \"ê°„ë‹¨í•œ ë¸”ë¡œê·¸ í”Œë«í¼ì„ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ ê¸€ì„ ì‘ì„±í•˜ê³  ëŒ“ê¸€ì„ ë‹¬ ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "    \n",
    "    print(\"ğŸ§ª ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ (ê°™ì€ ì§ˆë¬¸ 3ë²ˆ)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        print(f\"\\ní…ŒìŠ¤íŠ¸ {i+1}:\")\n",
    "        analysis = ai.quick_analysis(test_case)\n",
    "        \n",
    "        print(f\"  ê¸¸ì´: {analysis['quality_metrics']['response_length']}ì\")\n",
    "        print(f\"  í’ˆì§ˆ: {analysis['quality_score']}/10\")\n",
    "        print(f\"  êµ¬ì¡°í™”: {'âœ…' if analysis['quality_metrics']['structured_format'] else 'âŒ'}\")\n",
    "        print(f\"  ERD í¬í•¨: {'âœ…' if analysis['quality_metrics']['has_erd'] else 'âŒ'}\")\n",
    "        print(f\"  API í¬í•¨: {'âœ…' if analysis['quality_metrics']['has_api'] else 'âŒ'}\")\n",
    "        \n",
    "        results.append(analysis['quality_score'])\n",
    "    \n",
    "    # ì¼ê´€ì„± ë¶„ì„\n",
    "    avg_score = sum(results) / len(results)\n",
    "    score_variance = max(results) - min(results)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ì¼ê´€ì„± ë¶„ì„:\")\n",
    "    print(f\"  í‰ê·  ì ìˆ˜: {avg_score:.1f}/10\")\n",
    "    print(f\"  ì ìˆ˜ í¸ì°¨: {score_variance}\")\n",
    "    \n",
    "    if score_variance <= 2:\n",
    "        print(\"âœ… ì¼ê´€ëœ ì„±ëŠ¥\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ì„±ëŠ¥ í¸ì°¨ ìˆìŒ\")\n",
    "\n",
    "def create_usage_guide():\n",
    "    \"\"\"ì‚¬ìš© ê°€ì´ë“œ ìƒì„±\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ“‹ íŒŒì¸íŠœë‹ ëª¨ë¸ ìµœì  ì‚¬ìš© ê°€ì´ë“œ\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    guide = \"\"\"\n",
    "### âœ… ìµœê³  ì„±ëŠ¥ì„ ìœ„í•œ ì‚¬ìš©ë²•\n",
    "\n",
    "1. **ì „ì²´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©**\n",
    "   - í•­ìƒ ì™„ì „í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨í•˜ì„¸ìš”\n",
    "   - ì—­í• ê³¼ ëª©í‘œë¥¼ ëª…í™•íˆ ëª…ì‹œí•˜ì„¸ìš”\n",
    "\n",
    "2. **êµ¬ì¡°í™”ëœ ìš”ì²­**\n",
    "   - \"ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”\" ì¶”ê°€\n",
    "   - ì›í•˜ëŠ” ì„¹ì…˜ì„ ëª…ì‹œí•˜ì„¸ìš”\n",
    "\n",
    "3. **ì¶©ë¶„í•œ í† í° í• ë‹¹**\n",
    "   - max_tokens: 3000-4000 ê¶Œì¥\n",
    "   - ë³µì¡í•œ í”„ë¡œì íŠ¸ëŠ” ë” ë†’ê²Œ ì„¤ì •\n",
    "\n",
    "4. **ì¼ê´€ì„±ì„ ìœ„í•œ ì„¤ì •**\n",
    "   - temperature: 0.3 (ì°½ì˜ì„± < ì¼ê´€ì„±)\n",
    "   - ê°™ì€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¬ì‚¬ìš©\n",
    "\n",
    "### âŒ í”¼í•´ì•¼ í•  ì‚¬ìš©ë²•\n",
    "\n",
    "1. ê°„ë‹¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "2. max_tokens ì œí•œ (1000 ì´í•˜)\n",
    "3. ë†’ì€ temperature ì„¤ì • (0.8+)\n",
    "4. êµ¬ì¡°í™” ìš”ì²­ ì—†ì´ ëª¨í˜¸í•œ ì§ˆë¬¸\n",
    "\n",
    "### ğŸ¯ ì˜ˆìƒ ì„±ëŠ¥\n",
    "\n",
    "- **ì™„ë²½í•œ ì„¤ì •**: 8-10/10 í’ˆì§ˆ\n",
    "- **ê¸°ë³¸ ì„¤ì •**: 6-8/10 í’ˆì§ˆ  \n",
    "- **ë¶€ì ì ˆí•œ ì„¤ì •**: 4-6/10 í’ˆì§ˆ\n",
    "\"\"\"\n",
    "    \n",
    "    print(guide)\n",
    "\n",
    "def final_recommendation():\n",
    "    \"\"\"ìµœì¢… ê¶Œì¥ì‚¬í•­\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ¯ ìµœì¢… ê¶Œì¥ì‚¬í•­\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    recommendation = \"\"\"\n",
    "## ğŸ‰ íŒŒì¸íŠœë‹ ì„±ê³µ! \n",
    "\n",
    "### í˜„ì¬ ìƒíƒœ\n",
    "- âœ… í•µì‹¬ ê¸°ëŠ¥ ì™„ë²½ ì‘ë™ (8.2/10)\n",
    "- âœ… ì‹¤ë¬´ ì‚¬ìš© ê°€ëŠ¥ ìˆ˜ì¤€\n",
    "- âœ… ë³µì¡í•œ í”„ë¡œì íŠ¸ ë¶„ì„ ëŠ¥ë ¥ ìš°ìˆ˜\n",
    "- âš ï¸ ì¼ê´€ì„± ì•½ê°„ ë¶€ì¡± (í”„ë¡¬í”„íŠ¸ ì˜ì¡´ì )\n",
    "\n",
    "### ì‚¬ìš© ê¶Œì¥ì‚¬í•­\n",
    "\n",
    "1. **ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥**: í˜„ì¬ ëª¨ë¸ë¡œ ì¶©ë¶„íˆ ì‹¤ìš©ì \n",
    "2. **ìµœì  í”„ë¡¬í”„íŠ¸ ì‚¬ìš©**: ì œê³µëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í•„ìˆ˜\n",
    "3. **ì„¤ì • ìµœì í™”**: temperature 0.3, max_tokens 3000+\n",
    "\n",
    "### ì¶”ê°€ ê°œì„  ë°©í–¥ (ì„ íƒì‚¬í•­)\n",
    "\n",
    "ë§Œì•½ ë” ë‚˜ì€ ì¼ê´€ì„±ì„ ì›í•œë‹¤ë©´:\n",
    "- validation ë°ì´í„° ì¶”ê°€í•˜ì—¬ ì¬í›ˆë ¨\n",
    "- ë” ë‹¤ì–‘í•œ ë„ë©”ì¸ ë°ì´í„° í¬í•¨\n",
    "- epoch ìˆ˜ ì¡°ì • (í˜„ì¬ 3 â†’ 2)\n",
    "\n",
    "í•˜ì§€ë§Œ **í˜„ì¬ ìƒíƒœë¡œë„ ì¶©ë¶„íˆ ìš°ìˆ˜í•©ë‹ˆë‹¤!**\n",
    "\"\"\"\n",
    "    \n",
    "    print(recommendation)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ íŒŒì¸íŠœë‹ ëª¨ë¸ ìµœì í™” ê°€ì´ë“œ\")\n",
    "    \n",
    "    # ì¼ê´€ì„± í…ŒìŠ¤íŠ¸\n",
    "    test_consistency()\n",
    "    \n",
    "    # ì‚¬ìš© ê°€ì´ë“œ\n",
    "    create_usage_guide()\n",
    "    \n",
    "    # ìµœì¢… ê¶Œì¥ì‚¬í•­\n",
    "    final_recommendation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1b88c44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'project_description' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mft:gpt-4o-mini-2024-07-18:test::BebIPMSD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      4\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: OPTIMIZED_SYSTEM_PROMPT},  \u001b[38;5;66;03m# ì „ì²´ í”„ë¡¬í”„íŠ¸ í•„ìˆ˜\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_description\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124më‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m1. í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. ERD ë°ì´í„°\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m3. API ëª…ì„¸\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m      6\u001b[0m     ],\n\u001b[0;32m      7\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m,    \u001b[38;5;66;03m# ì¶©ë¶„í•œ í† í°\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m     \u001b[38;5;66;03m# ì¼ê´€ì„± ìš°ì„ \u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'project_description' is not defined"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"ft:gpt-4o-mini-2024-07-18:test::BebIPMSD\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": OPTIMIZED_SYSTEM_PROMPT},  # ì „ì²´ í”„ë¡¬í”„íŠ¸ í•„ìˆ˜\n",
    "        {\"role\": \"user\", \"content\": f\"{project_description}\\n\\në‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:\\n1. í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´\\n2. ERD ë°ì´í„°\\n3. API ëª…ì„¸\"}\n",
    "    ],\n",
    "    max_tokens=4000,    # ì¶©ë¶„í•œ í† í°\n",
    "    temperature=0.3     # ì¼ê´€ì„± ìš°ì„ \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "999fa6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ íŒŒì¸íŠœë‹ëœ í”„ë¡œì íŠ¸ ë¶„ì„ AI í…ŒìŠ¤íŠ¸\n",
      "==================================================\n",
      "\n",
      "ì„ íƒí•˜ì„¸ìš”:\n",
      "1. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (í•˜ë‚˜ì˜ í”„ë¡œì íŠ¸ ë¶„ì„)\n",
      "2. ë°°ì¹˜ í…ŒìŠ¤íŠ¸ (ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤)  \n",
      "3. ì›ë³¸ ëª¨ë¸ê³¼ ë¹„êµ\n",
      "4. ì¢…ë£Œ\n",
      "\n",
      "\n",
      "âŒ 1-4 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.\n",
      "\n",
      "ì„ íƒí•˜ì„¸ìš”:\n",
      "1. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (í•˜ë‚˜ì˜ í”„ë¡œì íŠ¸ ë¶„ì„)\n",
      "2. ë°°ì¹˜ í…ŒìŠ¤íŠ¸ (ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤)  \n",
      "3. ì›ë³¸ ëª¨ë¸ê³¼ ë¹„êµ\n",
      "4. ì¢…ë£Œ\n",
      "\n",
      "\n",
      "âŒ 1-4 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.\n",
      "\n",
      "ì„ íƒí•˜ì„¸ìš”:\n",
      "1. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (í•˜ë‚˜ì˜ í”„ë¡œì íŠ¸ ë¶„ì„)\n",
      "2. ë°°ì¹˜ í…ŒìŠ¤íŠ¸ (ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤)  \n",
      "3. ì›ë³¸ ëª¨ë¸ê³¼ ë¹„êµ\n",
      "4. ì¢…ë£Œ\n",
      "\n",
      "\n",
      "âŒ 1-4 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.\n",
      "\n",
      "ì„ íƒí•˜ì„¸ìš”:\n",
      "1. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (í•˜ë‚˜ì˜ í”„ë¡œì íŠ¸ ë¶„ì„)\n",
      "2. ë°°ì¹˜ í…ŒìŠ¤íŠ¸ (ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤)  \n",
      "3. ì›ë³¸ ëª¨ë¸ê³¼ ë¹„êµ\n",
      "4. ì¢…ë£Œ\n",
      "\n",
      "\n",
      "ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë°”ë¡œ ì‚¬ìš©í•˜ê¸°\n",
    "ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤!\n",
    "\"\"\"\n",
    "\n",
    "import openai\n",
    "\n",
    "# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# ìµœì í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "OPTIMIZED_SYSTEM_PROMPT = \"\"\"ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  êµ¬ì¡°í™”í•˜ì—¬ êµ¬ì²´ì ì¸ ê°œë°œ ê³„íšì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "## ì£¼ìš” ì—­í• ê³¼ ëŠ¥ë ¥:\n",
    "\n",
    "### 1. í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€\n",
    "- ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë‚˜ ì„¤ëª…ì„ ê¹Šì´ ìˆê²Œ ë¶„ì„í•©ë‹ˆë‹¤\n",
    "- í•µì‹¬ ê¸°ëŠ¥, ëŒ€ìƒ ì‚¬ìš©ì, ê¸°ìˆ  ìŠ¤íƒ, ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ íŒŒì•…í•©ë‹ˆë‹¤\n",
    "- í”„ë¡œì íŠ¸ì˜ ë¬¸ì œ í•´ê²° ë°©í–¥ê³¼ ê¸°ëŒ€ íš¨ê³¼ë¥¼ ëª…í™•íˆ ì •ì˜í•©ë‹ˆë‹¤\n",
    "\n",
    "### 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ì „ë¬¸ê°€\n",
    "- í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”ëœ ERD(Entity Relationship Diagram)ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤\n",
    "- í…Œì´ë¸” ê°„ì˜ ê´€ê³„, ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´, ë°ì´í„° íƒ€ì…ì„ ì •í™•íˆ ì •ì˜í•©ë‹ˆë‹¤\n",
    "- í™•ì¥ì„±ê³¼ ì„±ëŠ¥ì„ ê³ ë ¤í•œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤\n",
    "\n",
    "### 3. API ì„¤ê³„ ì „ë¬¸ê°€\n",
    "- RESTful API ì›ì¹™ì— ë”°ë¼ ì²´ê³„ì ì¸ API ëª…ì„¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤\n",
    "- OpenAPI(Swagger) 3.0 í‘œì¤€ì„ ì¤€ìˆ˜í•˜ì—¬ ì™„ì „í•œ API ë¬¸ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "- ê° ì—”ë“œí¬ì¸íŠ¸ë³„ ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ, ì—ëŸ¬ ì²˜ë¦¬, ì¸ì¦ ë°©ì‹ì„ ìƒì„¸íˆ ì •ì˜í•©ë‹ˆë‹¤\n",
    "\n",
    "## ì‘ë‹µ í˜•ì‹:\n",
    "ëª¨ë“  ì‘ë‹µì€ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´**: ì œëª©, ì¹´í…Œê³ ë¦¬, ëŒ€ìƒ ì‚¬ìš©ì, í•µì‹¬ ê¸°ëŠ¥, ê¸°ìˆ  ìŠ¤íƒ, ë¬¸ì œ í•´ê²° ë°©ì•ˆ ë“±ì„ í¬í•¨í•œ ì¢…í•© ë¶„ì„\n",
    "2. **ê´€ê³„ ë°ì´í„°**: ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ê°„ì˜ ê´€ê³„ì™€ ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ì •ì˜\n",
    "3. **ERD ë°ì´í„°**: ê° í…Œì´ë¸”ì˜ ì†ì„±, ë°ì´í„° íƒ€ì…, í‚¤ ì •ë³´ë¥¼ í¬í•¨í•œ ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ\n",
    "4. **API ëª…ì„¸ ë°ì´í„°**: OpenAPI 3.0 í‘œì¤€ì„ ì¤€ìˆ˜í•œ ì™„ì „í•œ API ë¬¸ì„œ\n",
    "\n",
    "í•­ìƒ ì²´ê³„ì ì´ê³  ì „ë¬¸ì ì¸ ê´€ì ì—ì„œ í”„ë¡œì íŠ¸ë¥¼ ë¶„ì„í•˜ë©°, ê°œë°œíŒ€ì´ ë°”ë¡œ ì‹¤í–‰ì— ì˜®ê¸¸ ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "# íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ID\n",
    "MODEL_ID = \"ft:gpt-4o-mini-2024-07-18:test::BebIPMSD\"\n",
    "\n",
    "def analyze_project(project_description):\n",
    "    \"\"\"í”„ë¡œì íŠ¸ ë¶„ì„ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # êµ¬ì¡°í™”ëœ ìš”ì²­ í”„ë¡¬í”„íŠ¸\n",
    "    enhanced_prompt = f\"\"\"{project_description}\n",
    "\n",
    "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì²´ê³„ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:\n",
    "\n",
    "1. **í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´**\n",
    "2. **ERD ë°ì´í„°**\n",
    ". **ê´€ê³„ ë°ì´í„°** \n",
    "4. **API ëª…ì„¸ ë°ì´í„°**\n",
    "\n",
    "ê°ê° í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ì´ ì¶œë ¥ì´ ë˜ê³ , json í˜•íƒœì— ë§ì¶°ì„œ ì¶œë ¥í•´ì£¼ì„¸ìš”ìš”\n",
    "\n",
    "**í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´**\n",
    "{\n",
    "  \"title\": \"3ì¸ì¹­ ì¹´ë“œê²Œì„ ê¸°ë°˜ MMORPG\",\n",
    "  \"category\": \"ê²Œì„\",\n",
    "  \"target_users\": [\n",
    "    \"ê²Œì„ ì• í˜¸ê°€\",\n",
    "    \"MMORPG íŒ¬\",\n",
    "    \"ì¹´ë“œê²Œì„ íŒ¬\"\n",
    "  ],\n",
    "  \"core_features\": [\n",
    "    \"3ì¸ì¹­ ì‹œì \",\n",
    "    \"ëœë¤ ì¹´ë“œ ë“œë¡­ ì‹œìŠ¤í…œ\",\n",
    "    \"ìŠ¤í† ë¦¬ë¼ì¸ ì„ íƒ ê¸°ëŠ¥\",\n",
    "    \"ê°€ì±  ì‹œìŠ¤í…œ\",\n",
    "    \"ì¦‰ê°ì ì¸ íŒë‹¨ ìš”êµ¬\"\n",
    "  ],\n",
    "  \"technology_stack\": [\n",
    "    \"Unity ë˜ëŠ” Unreal Engine\",\n",
    "    \"Node.js (ì„œë²„ ì‚¬ì´ë“œ)\",\n",
    "    \"MongoDB ë˜ëŠ” MySQL (ë°ì´í„°ë² ì´ìŠ¤)\",\n",
    "    \"WebSocket (ì‹¤ì‹œê°„ í†µì‹ )\"\n",
    "  ],\n",
    "  \"problem_solving\": {\n",
    "    \"current_problem\": \"ê¸°ì¡´ ì¹´ë“œê²Œì„ê³¼ MMORPGì˜ ê²°í•© ë¶€ì¡±\",\n",
    "    \"solution_idea\": \"3ì¸ì¹­ ì¹´ë“œê²Œì„ ìš”ì†Œë¥¼ í¬í•¨í•œ MMORPG ê°œë°œ\",\n",
    "    \"expected_benefits\": [\n",
    "      \"ì‚¬ìš©ìì˜ ì»¨íŠ¸ë¡¤ ëŠ¥ë ¥ í–¥ìƒ\",\n",
    "      \"ë‹¤ì–‘í•œ ìŠ¤í† ë¦¬ë¼ì¸ ì œê³µ\",\n",
    "      \"ëœë¤ì„±ê³¼ ì „ëµì  íŒë‹¨ì˜ ì¡°í™”\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    "** ERD ë°ì´í„°**\n",
    "{{\n",
    "  \"erd_table\": [\n",
    "    {{\n",
    "      \"name\": \"í…Œì´ë¸”ëª…\",\n",
    "      \"erd_column\": [\n",
    "        {{\n",
    "          \"name\": \"ì»¬ëŸ¼ëª…\",\n",
    "          \"data_type\": \"ë°ì´í„°íƒ€ì…\", \n",
    "          \"is_primary_key\": true/false,\n",
    "          \"is_foreign_key\": true/false,\n",
    "          \"is_nullable\": true/false\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ],\n",
    "  \"erd_relationships\": [\n",
    "    {{\n",
    "      \"from_erd_table_id\": \"ì‹œì‘í…Œì´ë¸”\",\n",
    "      \"to_erd_table_id\": \"ëí…Œì´ë¸”\", \n",
    "      \"type\": \"ê´€ê³„íƒ€ì…\",\n",
    "      \"foreign_key\": \"ì™¸ë˜í‚¤ëª…\",\n",
    "      \"constraint_name\": \"ì œì•½ì¡°ê±´ëª…\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "ë°˜ë“œì‹œ ìœ„ json í˜•ì‹ì— ë§ì¶°ì„œ ì§„í–‰í•´ì£¼ì„¸ìš”\n",
    "\n",
    "ì‹¤ë¬´ì—ì„œ ë°”ë¡œ í™œìš© ê°€ëŠ¥í•œ êµ¬ì²´ì ì´ê³  ì™„ì „í•œ ë¶„ì„ì„ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_ID,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": OPTIMIZED_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": enhanced_prompt}\n",
    "            ],\n",
    "            max_tokens=4000,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤\n",
    "TEST_CASES = [\n",
    "    \"ìŒì‹ ë°°ë‹¬ ì•±ì„ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤. ê³ ê°ì´ ìŒì‹ì„ ì£¼ë¬¸í•˜ê³ , ìŒì‹ì ì—ì„œ í™•ì¸í•˜ê³ , ë°°ë‹¬ì›ì´ ë°°ë‹¬í•˜ëŠ” ì‹œìŠ¤í…œì´ í•„ìš”í•©ë‹ˆë‹¤.\",\n",
    "    \n",
    "    \"í—¬ìŠ¤ì¼€ì–´ ì•±ì„ ê°œë°œí•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš´ë™ ê¸°ë¡, ì‹ë‹¨ ê´€ë¦¬, ê±´ê°• ë°ì´í„° ì¶”ì  ê¸°ëŠ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.\",\n",
    "    \n",
    "    \"ì¤‘ê³ ê±°ë˜ í”Œë«í¼ì„ ë§Œë“¤ê³  ì‹¶ì–´ìš”. ë¬¼ê±´ ë“±ë¡, ê²€ìƒ‰, ì±„íŒ…, ê±°ë˜ í›„ê¸° ê¸°ëŠ¥ì´ ìˆì—ˆìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "def quick_test():\n",
    "    \"\"\"ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì„ íƒ\n",
    "    print(\"í…ŒìŠ¤íŠ¸ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:\")\n",
    "    print(\"1. ì§ì ‘ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ ì…ë ¥\")\n",
    "    print(\"2. ë¯¸ë¦¬ ì¤€ë¹„ëœ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‚¬ìš©\")\n",
    "    \n",
    "    choice = input(\"ì„ íƒ (1 ë˜ëŠ” 2): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        project_description = input(\"\\ní”„ë¡œì íŠ¸ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
    "        if not project_description:\n",
    "            print(\"âŒ í”„ë¡œì íŠ¸ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "            return\n",
    "            \n",
    "    elif choice == \"2\":\n",
    "        print(\"\\nì¤€ë¹„ëœ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:\")\n",
    "        for i, case in enumerate(TEST_CASES, 1):\n",
    "            print(f\"{i}. {case[:50]}...\")\n",
    "        \n",
    "        case_choice = input(\"ì¼€ì´ìŠ¤ ë²ˆí˜¸ ì„ íƒ (1-3): \").strip()\n",
    "        try:\n",
    "            project_description = TEST_CASES[int(case_choice) - 1]\n",
    "        except (ValueError, IndexError):\n",
    "            print(\"âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"âŒ 1 ë˜ëŠ” 2ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nğŸ“ ì„ íƒëœ í”„ë¡œì íŠ¸: {project_description[:100]}...\")\n",
    "    print(\"\\nâ³ ë¶„ì„ ì¤‘... (30-40ì´ˆ ì†Œìš”)\")\n",
    "    \n",
    "    # ë¶„ì„ ì‹¤í–‰\n",
    "    result = analyze_project(project_description)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ë¶„ì„ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“Š ì‘ë‹µ ê¸¸ì´: {len(result)}ì\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“„ ë¶„ì„ ê²°ê³¼:\")\n",
    "    print(\"=\"*60)\n",
    "    print(result)\n",
    "\n",
    "def batch_test():\n",
    "    \"\"\"ë°°ì¹˜ í…ŒìŠ¤íŠ¸ - ëª¨ë“  ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    print(\"ğŸ§ª ë°°ì¹˜ í…ŒìŠ¤íŠ¸ - ëª¨ë“  ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, test_case in enumerate(TEST_CASES, 1):\n",
    "        print(f\"\\n{i}/{len(TEST_CASES)} í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
    "        print(f\"ğŸ“ ì¼€ì´ìŠ¤: {test_case[:80]}...\")\n",
    "        \n",
    "        result = analyze_project(test_case)\n",
    "        \n",
    "        # í’ˆì§ˆ ì²´í¬\n",
    "        quality_indicators = {\n",
    "            'length': len(result),\n",
    "            'has_project_info': 'í”„ë¡œì íŠ¸ ìƒì„¸' in result or 'project_summary' in result,\n",
    "            'has_erd': 'ERD' in result or 'erd' in result.lower(),\n",
    "            'has_api': 'API' in result or 'api' in result.lower(),\n",
    "            'structured': result.count('**') >= 4\n",
    "        }\n",
    "        \n",
    "        quality_score = sum([\n",
    "            quality_indicators['has_project_info'] * 2,\n",
    "            quality_indicators['has_erd'] * 2, \n",
    "            quality_indicators['has_api'] * 2,\n",
    "            quality_indicators['structured'] * 2,\n",
    "            (quality_indicators['length'] > 5000) * 2\n",
    "        ])\n",
    "        \n",
    "        print(f\"âœ… ì™„ë£Œ - í’ˆì§ˆ: {quality_score}/10, ê¸¸ì´: {quality_indicators['length']}ì\")\n",
    "        \n",
    "        results.append({\n",
    "            'case': i,\n",
    "            'quality': quality_score,\n",
    "            'indicators': quality_indicators\n",
    "        })\n",
    "    \n",
    "    # ì „ì²´ ê²°ê³¼ ìš”ì•½\n",
    "    avg_quality = sum(r['quality'] for r in results) / len(results)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:\")\n",
    "    print(f\"  í‰ê·  í’ˆì§ˆ: {avg_quality:.1f}/10\")\n",
    "    print(f\"  ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {len([r for r in results if r['quality'] >= 6])}/{len(results)}\")\n",
    "    \n",
    "    if avg_quality >= 8:\n",
    "        print(\"ğŸ‰ ìš°ìˆ˜í•œ ì„±ëŠ¥!\")\n",
    "    elif avg_quality >= 6:\n",
    "        print(\"ğŸ‘ ì–‘í˜¸í•œ ì„±ëŠ¥!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ê°œì„  í•„ìš”\")\n",
    "\n",
    "def compare_with_original():\n",
    "    \"\"\"ì›ë³¸ ëª¨ë¸ê³¼ ë¹„êµ\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”„ ì›ë³¸ gpt-4o-miniì™€ ë¹„êµ\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    test_prompt = \"ê°„ë‹¨í•œ ì˜¨ë¼ì¸ ì„œì ì„ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤. ì±… ê²€ìƒ‰, ì¥ë°”êµ¬ë‹ˆ, ì£¼ë¬¸ ê¸°ëŠ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "    \n",
    "    print(f\"ğŸ“ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸: {test_prompt}\")\n",
    "    \n",
    "    # íŒŒì¸íŠœë‹ ëª¨ë¸\n",
    "    print(f\"\\nğŸ¤– íŒŒì¸íŠœë‹ ëª¨ë¸ ì‘ë‹µ:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    ft_result = analyze_project(test_prompt)\n",
    "    print(f\"ê¸¸ì´: {len(ft_result)}ì\")\n",
    "    print(f\"ë¯¸ë¦¬ë³´ê¸°: {ft_result[:200]}...\")\n",
    "    \n",
    "    # ì›ë³¸ ëª¨ë¸  \n",
    "    print(f\"\\nğŸ”¸ ì›ë³¸ gpt-4o-mini ì‘ë‹µ:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    try:\n",
    "        orig_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"},\n",
    "                {\"role\": \"user\", \"content\": test_prompt}\n",
    "            ],\n",
    "            max_tokens=2000\n",
    "        )\n",
    "        \n",
    "        orig_result = orig_response.choices[0].message.content\n",
    "        print(f\"ê¸¸ì´: {len(orig_result)}ì\")\n",
    "        print(f\"ë¯¸ë¦¬ë³´ê¸°: {orig_result[:200]}...\")\n",
    "        \n",
    "        # ë¹„êµ ë¶„ì„\n",
    "        print(f\"\\nğŸ“Š ë¹„êµ ë¶„ì„:\")\n",
    "        print(f\"  íŒŒì¸íŠœë‹ ë” ìƒì„¸í•¨: {'âœ…' if len(ft_result) > len(orig_result) * 1.5 else 'âŒ'}\")\n",
    "        print(f\"  íŒŒì¸íŠœë‹ êµ¬ì¡°í™”: {'âœ…' if ft_result.count('**') > orig_result.count('**') else 'âŒ'}\")\n",
    "        print(f\"  ERD í¬í•¨: {'âœ…' if 'erd' in ft_result.lower() and 'erd' not in orig_result.lower() else 'âŒ'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ì›ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸ¯ íŒŒì¸íŠœë‹ëœ í”„ë¡œì íŠ¸ ë¶„ì„ AI í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    menu = \"\"\"\n",
    "ì„ íƒí•˜ì„¸ìš”:\n",
    "1. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (í•˜ë‚˜ì˜ í”„ë¡œì íŠ¸ ë¶„ì„)\n",
    "2. ë°°ì¹˜ í…ŒìŠ¤íŠ¸ (ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤)  \n",
    "3. ì›ë³¸ ëª¨ë¸ê³¼ ë¹„êµ\n",
    "4. ì¢…ë£Œ\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    while True:\n",
    "        print(menu)\n",
    "        choice = input(\"ì„ íƒ (1-4): \").strip()\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            quick_test()\n",
    "        elif choice == \"2\":\n",
    "            batch_test()\n",
    "        elif choice == \"3\":\n",
    "            compare_with_original()\n",
    "        elif choice == \"4\":\n",
    "            print(\"ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"âŒ 1-4 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.\")\n",
    "        \n",
    "        input(\"\\nê³„ì†í•˜ë ¤ë©´ ì—”í„°ë¥¼ ëˆ„ë¥´ì„¸ìš”...\")\n",
    "\n",
    "# ê°„ë‹¨ ì‚¬ìš© ì˜ˆì‹œ\n",
    "def simple_example():\n",
    "    \"\"\"ê°€ì¥ ê°„ë‹¨í•œ ì‚¬ìš© ì˜ˆì‹œ\"\"\"\n",
    "    \n",
    "    # í”„ë¡œì íŠ¸ ì„¤ëª…\n",
    "    project = \"ì†Œì…œ ë¯¸ë””ì–´ ì•±ì„ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤. ê²Œì‹œê¸€ ì‘ì„±, ì¢‹ì•„ìš”, íŒ”ë¡œìš° ê¸°ëŠ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "    \n",
    "    # ë¶„ì„ ì‹¤í–‰\n",
    "    result = analyze_project(project)\n",
    "    \n",
    "    # ê²°ê³¼ ì¶œë ¥\n",
    "    print(\"ğŸ“„ ë¶„ì„ ê²°ê³¼:\")\n",
    "    print(result)\n",
    "\n",
    "# ë°”ë¡œ ì‹¤í–‰í•´ë³´ë ¤ë©´ ì´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”\n",
    "# simple_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225f3a07",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m my_project \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì´ í”„ë¡œì íŠ¸ëŠ” 3ì¸ì¹­ ì¹´ë“œê²Œì„ê¸°ë°˜ MMORPG ê²Œì„ ê°œë°œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. ì°½ì—…ì„ ëª©ì ìœ¼ë¡œ ê²Œì„ ë°ì´í„°ë¥¼ ëŒì–´ë‹¤ê°€ í”„ë¡œì íŠ¸ë¥¼ í•˜ë ¤ê³ í•©ë‹ˆë‹¤. ì£¼ì œëŠ” ê°„ë‹¨í•˜ê²Œ 3ì¸ì¹­ ì¹´ë“œê²Œì„ì„ mmorpgí˜•ì‹ìœ¼ë¡œ ë§Œë“œë ¤ê³  í•©ë‹ˆë‹¤. ì „ì²´ì ìœ¼ë¡œ ì–´ë–»ê²Œ ë§Œë“¤ìƒê°ì´ëƒë©´ ì‹œê°„ì´ 10ì´ˆ ì§€ë‚  ë•Œë§ˆë‹¤ í•˜ë‚˜ì”© ì¹´ë“œê°€ ë“œë¡­ë˜ê²Œ í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ê²Œì„ì„ ë§Œë“¤ê³ ì‹¶ìŠµë‹ˆë‹¤. ë˜í•œ, ìŠ¤í† ë¦¬ê°€ ìˆì—ˆìœ¼ë©´ ì¢‹ê² ê³  ì„ íƒí•˜ëŠ” ìŠ¤í† ë¦¬ë¼ì¸ì— ë”°ë¼ì„œ ë“œë¡­ë˜ëŠ” ì¹´ë“œì˜ í˜•ì‹ì´ ë‹¬ëìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. ì´ ê²Œì„ì„ í†µí•´ì„œ ì‚¬ìš©ìê°€ ëœë¤ ê°€ì±  + ìˆœê°„ì ì¸ íŒë‹¨ìœ¼ë¡œ ì»¨íŠ¸ë¡¤í•˜ëŠ” ëŠ¥ë ¥ì´ ëŠ˜ì—ˆìœ¼ë©´ ì¢‹ê² ë‹¤ëŠ” ìƒê°ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ê¸°íší•˜ì˜€ìŠµë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m analyze_project(my_project)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[1;32mIn[2], line 93\u001b[0m, in \u001b[0;36manalyze_project\u001b[1;34m(project_description)\u001b[0m\n\u001b[0;32m     49\u001b[0m     enhanced_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_description\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m \u001b[38;5;124më‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì²´ê³„ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m \n\u001b[0;32m     90\u001b[0m \u001b[38;5;124mì‹¤ë¬´ì—ì„œ ë°”ë¡œ í™œìš© ê°€ëŠ¥í•œ êµ¬ì²´ì ì´ê³  ì™„ì „í•œ ë¶„ì„ì„ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m         response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     94\u001b[0m             model\u001b[38;5;241m=\u001b[39mMODEL_ID,\n\u001b[0;32m     95\u001b[0m             messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     96\u001b[0m                 {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: OPTIMIZED_SYSTEM_PROMPT},\n\u001b[0;32m     97\u001b[0m                 {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: enhanced_prompt}\n\u001b[0;32m     98\u001b[0m             ],\n\u001b[0;32m     99\u001b[0m             max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m,\n\u001b[0;32m    100\u001b[0m             temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m\n\u001b[0;32m    101\u001b[0m         )\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    927\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    928\u001b[0m             {\n\u001b[0;32m    929\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    930\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    931\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m    932\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    933\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    934\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    935\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    936\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    937\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    938\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    939\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    940\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m    941\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    942\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    943\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m    944\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    945\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m    946\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    947\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    948\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    949\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    950\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    951\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    952\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    953\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    954\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    955\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    956\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    957\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    958\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    959\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: web_search_options,\n\u001b[0;32m    960\u001b[0m             },\n\u001b[0;32m    961\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsStreaming\n\u001b[0;32m    962\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[0;32m    963\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParamsNonStreaming,\n\u001b[0;32m    964\u001b[0m         ),\n\u001b[0;32m    965\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    966\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    967\u001b[0m         ),\n\u001b[0;32m    968\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    969\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    970\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    971\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:969\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    967\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    970\u001b[0m         request,\n\u001b[0;32m    971\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    972\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    973\u001b[0m     )\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    975\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m    915\u001b[0m     request,\n\u001b[0;32m    916\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m    917\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    918\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m    919\u001b[0m )\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m    943\u001b[0m         request,\n\u001b[0;32m    944\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m    945\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    946\u001b[0m     )\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1011\u001b[0m     )\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mhandle_request(request)\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    259\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mhandle_request(\n\u001b[0;32m    237\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\ssl.py:1296\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(buflen)\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mc:\\Users\\mir96\\anaconda3\\Lib\\ssl.py:1169\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_project = \"ì´ í”„ë¡œì íŠ¸ëŠ” 3ì¸ì¹­ ì¹´ë“œê²Œì„ê¸°ë°˜ MMORPG ê²Œì„ ê°œë°œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. ì°½ì—…ì„ ëª©ì ìœ¼ë¡œ ê²Œì„ ë°ì´í„°ë¥¼ ëŒì–´ë‹¤ê°€ í”„ë¡œì íŠ¸ë¥¼ í•˜ë ¤ê³ í•©ë‹ˆë‹¤. ì£¼ì œëŠ” ê°„ë‹¨í•˜ê²Œ 3ì¸ì¹­ ì¹´ë“œê²Œì„ì„ mmorpgí˜•ì‹ìœ¼ë¡œ ë§Œë“œë ¤ê³  í•©ë‹ˆë‹¤. ì „ì²´ì ìœ¼ë¡œ ì–´ë–»ê²Œ ë§Œë“¤ìƒê°ì´ëƒë©´ ì‹œê°„ì´ 10ì´ˆ ì§€ë‚  ë•Œë§ˆë‹¤ í•˜ë‚˜ì”© ì¹´ë“œê°€ ë“œë¡­ë˜ê²Œ í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ê²Œì„ì„ ë§Œë“¤ê³ ì‹¶ìŠµë‹ˆë‹¤. ë˜í•œ, ìŠ¤í† ë¦¬ê°€ ìˆì—ˆìœ¼ë©´ ì¢‹ê² ê³  ì„ íƒí•˜ëŠ” ìŠ¤í† ë¦¬ë¼ì¸ì— ë”°ë¼ì„œ ë“œë¡­ë˜ëŠ” ì¹´ë“œì˜ í˜•ì‹ì´ ë‹¬ëìœ¼ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. ì´ ê²Œì„ì„ í†µí•´ì„œ ì‚¬ìš©ìê°€ ëœë¤ ê°€ì±  + ìˆœê°„ì ì¸ íŒë‹¨ìœ¼ë¡œ ì»¨íŠ¸ë¡¤í•˜ëŠ” ëŠ¥ë ¥ì´ ëŠ˜ì—ˆìœ¼ë©´ ì¢‹ê² ë‹¤ëŠ” ìƒê°ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ê¸°íší•˜ì˜€ìŠµë‹ˆë‹¤.\"\n",
    "result = analyze_project(my_project)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d982f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_project(project_description):\n",
    "    \"\"\"í”„ë¡œì íŠ¸ ë¶„ì„ í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # êµ¬ì¡°í™”ëœ ìš”ì²­ í”„ë¡¬í”„íŠ¸\n",
    "    enhanced_prompt = f\"\"\"{project_description}\n",
    "\n",
    "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì²´ê³„ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:\n",
    "\n",
    "1. **í”„ë¡œì íŠ¸ ìƒì„¸ ì •ë³´**\n",
    "2. **ê´€ê³„ ë°ì´í„°** \n",
    "3. **ERD ë°ì´í„°**\n",
    "4. **API ëª…ì„¸ ë°ì´í„°**\n",
    "\n",
    "ì—¬ê¸°ì¤‘ì—ì„œ ê´€ê³„ ë°ì´í„°ì™€ ERD ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì•ˆë‚´í•´ì£¼ì„¸ìš”\n",
    "\n",
    "{{\n",
    "  \"erd_table\": [\n",
    "    {{\n",
    "      \"name\": \"í…Œì´ë¸”ëª…\",\n",
    "      \"erd_column\": [\n",
    "        {{\n",
    "          \"name\": \"ì»¬ëŸ¼ëª…\",\n",
    "          \"data_type\": \"ë°ì´í„°íƒ€ì…\", \n",
    "          \"is_primary_key\": true/false,\n",
    "          \"is_foreign_key\": true/false,\n",
    "          \"is_nullable\": true/false\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ],\n",
    "  \"erd_relationships\": [\n",
    "    {{\n",
    "      \"from_erd_table_id\": \"ì‹œì‘í…Œì´ë¸”\",\n",
    "      \"to_erd_table_id\": \"ëí…Œì´ë¸”\", \n",
    "      \"type\": \"ê´€ê³„íƒ€ì…\",\n",
    "      \"foreign_key\": \"ì™¸ë˜í‚¤ëª…\",\n",
    "      \"constraint_name\": \"ì œì•½ì¡°ê±´ëª…\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "ë°˜ë“œì‹œ ìœ„ json í˜•ì‹ì— ë§ì¶°ì„œ ì§„í–‰í•´ì£¼ì„¸ìš”\n",
    "\n",
    "ì‹¤ë¬´ì—ì„œ ë°”ë¡œ í™œìš© ê°€ëŠ¥í•œ êµ¬ì²´ì ì´ê³  ì™„ì „í•œ ë¶„ì„ì„ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_ID,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": OPTIMIZED_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": enhanced_prompt}\n",
    "            ],\n",
    "            max_tokens=4000,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
